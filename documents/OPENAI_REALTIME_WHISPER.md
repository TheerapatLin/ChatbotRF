# OpenAI Realtime Whisper Implementation Guide

**‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô**: 1.0
**‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á**: 2025-11-10
**‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞**: üìù Planning Phase

---

## üìã ‡∏™‡∏≤‡∏£‡∏ö‡∏±‡∏ç

1. [‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°](#‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°)
2. [‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á OpenAI Realtime API](#‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á-openai-realtime-api)
3. [‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Transcription](#‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£-transcription)
4. [‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö](#‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö)
5. [‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ](#‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ)
6. [Implementation Tasks](#implementation-tasks)
7. [‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå](#‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå)
8. [‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö](#‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö)
9. [‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á](#‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á)

---

## ‡∏†‡∏≤‡∏û‡∏£‡∏ß‡∏°

OpenAI Realtime API ‡πÄ‡∏õ‡πá‡∏ô WebSocket-based API ‡∏ó‡∏µ‡πà‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á (Speech-to-Text Transcription) ‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡πà‡∏ß‡∏á‡∏ï‡πà‡∏≥ (Low Latency: 300-800ms) ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö:

- **Live Captioning**: ‡∏Å‡∏≤‡∏£‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏™‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°, ‡∏á‡∏≤‡∏ô‡∏™‡∏±‡∏°‡∏°‡∏ô‡∏≤
- **Voice Assistants**: ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
- **Meeting Transcription**: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏∏‡∏°‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå
- **Call Center Analytics**: ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏•‡∏π‡∏Å‡∏Ñ‡πâ‡∏≤
- **Interactive Voice Applications**: ‡πÅ‡∏≠‡∏õ‡∏û‡∏•‡∏¥‡πÄ‡∏Ñ‡∏ä‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏õ‡∏è‡∏¥‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡∏ó‡∏±‡∏ô‡∏ó‡∏µ

### ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö

| ‡πÇ‡∏°‡πÄ‡∏î‡∏• | ‡∏Ñ‡∏∏‡∏ì‡∏™‡∏°‡∏ö‡∏±‡∏ï‡∏¥ | Latency | ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ | ‡∏£‡∏≤‡∏Ñ‡∏≤ | Use Case |
|-------|-----------|---------|-----------|------|----------|
| **gpt-4o-transcribe** | Full-featured, state-of-the-art | ~500-800ms | ‡∏™‡∏π‡∏á‡∏°‡∏≤‡∏Å (99%+) | ‡∏™‡∏π‡∏á‡∏Å‡∏ß‡πà‡∏≤ | Production, Meeting transcription, ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç |
| **gpt-4o-mini-transcribe** | Lightweight, faster | ~300-500ms | ‡∏™‡∏π‡∏á (95-98%) | ‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ | Testing, Voice commands, Real-time captions |

---

## ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏Ç‡∏≠‡∏á OpenAI Realtime API

### 1. Architecture Flow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         WebSocket          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Client    ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí  ‚îÇ  OpenAI API     ‚îÇ
‚îÇ  (Browser/  ‚îÇ   wss://api.openai.com    ‚îÇ  Realtime       ‚îÇ
‚îÇ   Mobile)   ‚îÇ   /v1/realtime            ‚îÇ  Transcription  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                            ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ                                              ‚îÇ
      ‚îÇ 1. Audio Capture (Mic)                      ‚îÇ
      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ
      ‚îÇ                                              ‚îÇ
      ‚îÇ 2. Encode to PCM16 24kHz                    ‚îÇ
      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ
      ‚îÇ                                              ‚îÇ
      ‚îÇ 3. Base64 Encode & Send via WebSocket      ‚îÇ
      ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ
      ‚îÇ                                              ‚îÇ
      ‚îÇ                          4. Process Audio   ‚îÇ
      ‚îÇ                          ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
      ‚îÇ                                              ‚îÇ
      ‚îÇ 5. Partial Transcription (Streaming)        ‚îÇ
      ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
      ‚îÇ   {"type": "partial", "text": "hello..."}   ‚îÇ
      ‚îÇ                                              ‚îÇ
      ‚îÇ 6. Final Transcription                      ‚îÇ
      ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
      ‚îÇ   {"type": "final", "text": "hello world"}  ‚îÇ
      ‚îÇ                                              ‚îÇ
      ‚îÇ 7. Display/Process Result                   ‚îÇ
      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 2. WebSocket Connection Lifecycle

#### Phase 1: Connection & Session Setup

```javascript
// 1. ‡∏™‡∏£‡πâ‡∏≤‡∏á WebSocket connection
const ws = new WebSocket(
  'wss://api.openai.com/v1/realtime?intent=transcription',
  {
    headers: {
      'Authorization': 'Bearer YOUR_OPENAI_API_KEY',
      'OpenAI-Beta': 'realtime=v1'
    }
  }
);

// 2. ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏™‡πà‡∏á session configuration
ws.on('open', () => {
  ws.send(JSON.stringify({
    type: 'session.update',
    session: {
      model: 'gpt-4o-mini-transcribe',
      intent: 'transcription',
      input_audio_format: 'pcm16',
      output_audio_format: 'pcm16',
      input_audio_transcription: {
        model: 'gpt-4o-mini-transcribe',
        language: 'en',  // ‡∏´‡∏£‡∏∑‡∏≠ 'th' ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢
      },
      turn_detection: {
        type: 'server_vad',
        threshold: 0.5,
        prefix_padding_ms: 300,
        silence_duration_ms: 500
      },
      input_audio_noise_reduction: 'near_field'  // 'near_field' ‡∏´‡∏£‡∏∑‡∏≠ 'far_field'
    }
  }));
});
```

**‡∏Ñ‡∏≥‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Parameters:**
- `intent: 'transcription'` - ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
- `input_audio_format: 'pcm16'` - ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö (PCM 16-bit)
- `language: 'en'` - ‡∏†‡∏≤‡∏©‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏° (auto-detect ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏)
- `turn_detection.type: 'server_vad'` - ‡πÉ‡∏ä‡πâ Voice Activity Detection ‡∏ù‡∏±‡πà‡∏á server
- `turn_detection.silence_duration_ms: 500` - ‡∏´‡∏¢‡∏∏‡∏î‡∏£‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏´‡∏•‡∏±‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö 500ms
- `input_audio_noise_reduction: 'near_field'` - ‡∏•‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏£‡∏ö‡∏Å‡∏ß‡∏ô‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏°‡∏Ñ‡πå‡πÉ‡∏Å‡∏•‡πâ

#### Phase 2: Audio Streaming

```javascript
// 3. ‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å microphone
navigator.mediaDevices.getUserMedia({ audio: true })
  .then(stream => {
    const audioContext = new AudioContext({ sampleRate: 24000 });
    const source = audioContext.createMediaStreamSource(stream);
    const processor = audioContext.createScriptProcessor(4096, 1, 1);

    processor.onaudioprocess = (e) => {
      // Convert Float32Array to Int16Array (PCM16)
      const float32 = e.inputBuffer.getChannelData(0);
      const int16 = new Int16Array(float32.length);

      for (let i = 0; i < float32.length; i++) {
        const s = Math.max(-1, Math.min(1, float32[i]));
        int16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
      }

      // Base64 encode ‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô WebSocket
      const base64Audio = btoa(
        String.fromCharCode.apply(null, new Uint8Array(int16.buffer))
      );

      ws.send(JSON.stringify({
        type: 'input_audio_buffer.append',
        audio: base64Audio
      }));
    };

    source.connect(processor);
    processor.connect(audioContext.destination);
  });
```

#### Phase 3: Receiving Transcriptions

```javascript
// 4. ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ö‡∏ö streaming
ws.on('message', (message) => {
  const event = JSON.parse(message);

  switch(event.type) {
    case 'input_audio_buffer.speech_started':
      console.log('üé§ User started speaking');
      break;

    case 'input_audio_buffer.speech_stopped':
      console.log('üîá User stopped speaking');
      break;

    case 'conversation.item.input_audio_transcription.partial':
      // Partial transcription (‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏π‡∏î)
      console.log('üìù Partial:', event.transcript);
      updateTranscript(event.transcript, false);
      break;

    case 'conversation.item.input_audio_transcription.final':
      // Final transcription (‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå)
      console.log('‚úÖ Final:', event.transcript);
      updateTranscript(event.transcript, true);

      // Optional: Log probabilities for confidence
      if (event.logprobs) {
        const avgConfidence = calculateConfidence(event.logprobs);
        console.log('üìä Confidence:', avgConfidence);
      }
      break;

    case 'error':
      console.error('‚ùå Error:', event.error);
      break;
  }
});

function updateTranscript(text, isFinal) {
  const transcriptDiv = document.getElementById('transcript');
  if (isFinal) {
    transcriptDiv.innerHTML += `<p class="final">${text}</p>`;
  } else {
    // ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï partial transcript (‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏µ‡∏¢‡∏á)
    const partial = transcriptDiv.querySelector('.partial');
    if (partial) {
      partial.textContent = text;
    } else {
      transcriptDiv.innerHTML += `<p class="partial"><em>${text}</em></p>`;
    }
  }
}
```

### 3. Event Types & Message Format

#### Client ‚Üí Server Events

| Event Type | Description | Payload |
|-----------|-------------|---------|
| `session.update` | ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï session configuration | `{ type, session: {...} }` |
| `input_audio_buffer.append` | ‡∏™‡πà‡∏á audio chunk | `{ type, audio: "base64..." }` |
| `input_audio_buffer.commit` | ‡∏¢‡∏∑‡∏ô‡∏¢‡∏±‡∏ô‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏™‡πà‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á | `{ type }` |
| `input_audio_buffer.clear` | ‡∏•‡πâ‡∏≤‡∏á buffer | `{ type }` |

#### Server ‚Üí Client Events

| Event Type | Description | Data |
|-----------|-------------|------|
| `session.created` | Session ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à | Session ID, config |
| `input_audio_buffer.speech_started` | ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô | Timestamp |
| `input_audio_buffer.speech_stopped` | ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡∏´‡∏¢‡∏∏‡∏î | Timestamp, audio duration |
| `conversation.item.input_audio_transcription.partial` | ‡∏ú‡∏• transcription ‡πÅ‡∏ö‡∏ö partial | `{ transcript, item_id }` |
| `conversation.item.input_audio_transcription.final` | ‡∏ú‡∏• transcription ‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ | `{ transcript, item_id, logprobs }` |
| `error` | ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î | `{ error: {type, message} }` |

---

## ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£ Transcription

### 1. OpenAI Whisper API (Current Implementation)

**‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á**: `backend/services/openai_service.go` ‚Üí `TranscribeAudio()`

```go
// POST /api/audio/transcribe
func (s *OpenAIService) TranscribeAudio(file io.Reader, filename string) (*TranscriptionResponse, error) {
    req := openai.AudioRequest{
        Model:    openai.Whisper1,
        FilePath: filename,
        Reader:   file,
    }
    resp, err := s.client.CreateTranscription(ctx, req)
    // ...
}
```

**‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**
- üìÅ Upload ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏±‡πâ‡∏á‡πÑ‡∏ü‡∏•‡πå (HTTP POST)
- ‚è±Ô∏è ‡∏£‡∏≠‡∏à‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏£‡πá‡∏à ‚Üí ‡∏≠‡∏±‡∏û‡πÇ‡∏´‡∏•‡∏î ‚Üí ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
- üîÑ Latency: 3-10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏Å‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÑ‡∏ü‡∏•‡πå)

**Use Cases:**
- ‚úÖ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß (Recorded audio)
- ‚úÖ ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
- ‚úÖ ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ real-time feedback

### 2. OpenAI Realtime API (New - To Be Implemented)

```
WebSocket Connection ‚Üí Streaming Audio ‚Üí Partial + Final Results
```

**‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**
- üé§ Stream ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö real-time ‡∏ú‡πà‡∏≤‡∏ô WebSocket
- üìù ‡πÑ‡∏î‡πâ‡∏ú‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏Ç‡∏ì‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏π‡∏î (Partial transcription)
- ‚ö° Latency: 300-800ms

**Use Cases:**
- ‚úÖ Live transcription (‡∏Ñ‡∏≥‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏™‡∏î)
- ‚úÖ Voice commands ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏≠‡∏ö‡∏™‡∏ô‡∏≠‡∏á‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
- ‚úÖ Interactive conversations

### 3. Whisper.cpp (Local Implementation)

**‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á**: `backend/whisper/` (‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 1-2 ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß)

```bash
./backend/whisper/binary/linux/main -m model.bin -f audio.wav
```

**‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô:**
- üíª ‡∏£‡∏±‡∏ô‡∏ö‡∏ô server ‡πÄ‡∏≠‡∏á (‡πÑ‡∏°‡πà‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API)
- üîí ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏≠‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å server
- ‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏ñ‡πâ‡∏≤‡∏°‡∏µ GPU

**Use Cases:**
- ‚úÖ Privacy-sensitive data
- ‚úÖ Offline deployment
- ‚úÖ ‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢ API

### ‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö

| Feature | Whisper API | Realtime API | Whisper.cpp |
|---------|-------------|--------------|-------------|
| **Connection** | HTTP POST | WebSocket | Local Process |
| **Latency** | 3-10s | 300-800ms | 2-5s (CPU), <1s (GPU) |
| **Streaming** | ‚ùå | ‚úÖ | ‚ùå |
| **Partial Results** | ‚ùå | ‚úÖ | ‚ùå |
| **File Size Limit** | 25 MB | Unlimited (stream) | Unlimited |
| **Cost** | $0.006/min | $0.10/min (4o), $0.01/min (mini) | ‡∏ü‡∏£‡∏µ (infrastructure only) |
| **Privacy** | ‚ùå ‡∏™‡πà‡∏á‡πÑ‡∏õ OpenAI | ‚ùå ‡∏™‡πà‡∏á‡πÑ‡∏õ OpenAI | ‚úÖ ‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô server |
| **Languages** | 99+ | 99+ | 99+ |
| **Setup Complexity** | ‚≠ê ‡∏á‡πà‡∏≤‡∏¢ | ‚≠ê‚≠ê ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á | ‚≠ê‚≠ê‚≠ê ‡∏ã‡∏±‡∏ö‡∏ã‡πâ‡∏≠‡∏ô |
| **Use Case** | Batch processing | Real-time UI | Privacy/Offline |

---

## ‡∏™‡∏ñ‡∏≤‡∏õ‡∏±‡∏ï‡∏¢‡∏Å‡∏£‡∏£‡∏°‡∏£‡∏∞‡∏ö‡∏ö

### Current Architecture (Whisper API)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   HTTP POST    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   HTTP POST    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ Backend  ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ OpenAI      ‚îÇ
‚îÇ (Vue.js) ‚îÇ                ‚îÇ (Go)     ‚îÇ                ‚îÇ Whisper API ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                            ‚îÇ                             ‚îÇ
     ‚îÇ 1. Record audio            ‚îÇ                             ‚îÇ
     ‚îÇ 2. Upload file             ‚îÇ                             ‚îÇ
     ‚îÇ                            ‚îÇ 3. Forward to OpenAI        ‚îÇ
     ‚îÇ                            ‚îÇ                             ‚îÇ
     ‚îÇ                            ‚îÇ 4. Wait for response        ‚îÇ
     ‚îÇ                            ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
     ‚îÇ 5. Return transcript       ‚îÇ                             ‚îÇ
     ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ                             ‚îÇ

‚è±Ô∏è Total Latency: 3-10 seconds
```

### Proposed Architecture (Realtime API)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   WebSocket    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   WebSocket    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Frontend ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ Backend  ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ OpenAI      ‚îÇ
‚îÇ (Vue.js) ‚îÇ  (ws://...)    ‚îÇ (Go)     ‚îÇ  (wss://...)   ‚îÇ Realtime    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ                            ‚îÇ                             ‚îÇ
     ‚îÇ 1. Capture audio (mic)     ‚îÇ                             ‚îÇ
     ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ                             ‚îÇ
     ‚îÇ 2. Stream PCM chunks       ‚îÇ                             ‚îÇ
     ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí ‚îÇ 3. Forward to OpenAI       ‚îÇ
     ‚îÇ                            ‚îÇ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ
     ‚îÇ                            ‚îÇ                             ‚îÇ
     ‚îÇ                            ‚îÇ 4. Partial transcript       ‚îÇ
     ‚îÇ 5. Update UI (streaming)   ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ
     ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ                             ‚îÇ
     ‚îÇ (‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏Ç‡∏ì‡∏∞‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏π‡∏î)         ‚îÇ                             ‚îÇ
     ‚îÇ                            ‚îÇ                             ‚îÇ
     ‚îÇ 6. Final transcript         ‚îÇ                             ‚îÇ
     ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ ‚îÇ

‚ö° Latency per chunk: 300-800ms
```

### Hybrid Architecture (‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥)

```
                        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ      Frontend (Vue.js)    ‚îÇ
                        ‚îÇ                          ‚îÇ
                        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
                        ‚îÇ  ‚îÇ Audio Recorder      ‚îÇ ‚îÇ
                        ‚îÇ  ‚îÇ - MediaRecorder API ‚îÇ ‚îÇ
                        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                        ‚îÇ           ‚îÇ              ‚îÇ
                        ‚îÇ           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                        ‚îÇ           ‚îÇ              ‚îÇ      ‚îÇ
                        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
                                    ‚îÇ                     ‚îÇ
                            (Switch Mode)                 ‚îÇ
                                    ‚îÇ                     ‚îÇ
                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
                   ‚îÇ                          ‚îÇ          ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
        ‚îÇ  Batch Mode        ‚îÇ    ‚îÇ  Realtime Mode     ‚îÇ‚îÇ
        ‚îÇ  (HTTP POST)       ‚îÇ    ‚îÇ  (WebSocket)       ‚îÇ‚îÇ
        ‚îÇ                    ‚îÇ    ‚îÇ                    ‚îÇ‚îÇ
        ‚îÇ  /api/audio/       ‚îÇ    ‚îÇ  /ws/realtime/     ‚îÇ‚îÇ
        ‚îÇ  transcribe        ‚îÇ    ‚îÇ  transcribe        ‚îÇ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
                 ‚îÇ                         ‚îÇ            ‚îÇ
                 ‚îÇ  Backend (Go Fiber)     ‚îÇ            ‚îÇ
                 ‚îÇ                         ‚îÇ            ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îê
        ‚îÇ OpenAI Service   ‚îÇ    ‚îÇ Realtime Service       ‚îÇ
        ‚îÇ (openai_service) ‚îÇ    ‚îÇ (realtime_service)     ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ                         ‚îÇ
                 ‚îÇ  HTTP                   ‚îÇ  WebSocket
                 ‚îÇ                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ          OpenAI API                           ‚îÇ
        ‚îÇ                                               ‚îÇ
        ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
        ‚îÇ  ‚îÇ Whisper API     ‚îÇ  ‚îÇ Realtime API     ‚îÇ  ‚îÇ
        ‚îÇ  ‚îÇ (whisper-1)     ‚îÇ  ‚îÇ (gpt-4o-         ‚îÇ  ‚îÇ
        ‚îÇ  ‚îÇ                 ‚îÇ  ‚îÇ  transcribe)     ‚îÇ  ‚îÇ
        ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Use Case Selection:
‚îú‚îÄ Batch Mode: Recorded audio files, non-urgent transcription
‚îî‚îÄ Realtime Mode: Live captions, voice commands, meetings
```

---

## ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ó‡∏≤‡∏á‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ

### 1. Audio Format Requirements

#### Input Audio (Client ‚Üí Server)

```
Format:      PCM16 (16-bit Pulse Code Modulation)
Sample Rate: 24000 Hz (24 kHz) - ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥
             16000 Hz (16 kHz) - ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö
Channels:    1 (Mono)
Bit Depth:   16-bit
Byte Order:  Little-endian
Encoding:    Base64 (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô WebSocket)
Chunk Size:  4096 samples (~170ms @ 24kHz)
             2048 samples (~128ms @ 16kHz)
```

#### Audio Processing Pipeline

```
[Microphone]
      ‚Üì
[AudioContext (Browser API)]
  - Sample Rate: 24000 Hz
  - Format: Float32 (-1.0 to 1.0)
      ‚Üì
[ScriptProcessor / AudioWorklet]
  - Convert Float32 ‚Üí Int16
  - Formula: int16 = float32 * 32767
      ‚Üì
[Base64 Encoding]
  - Convert Int16Array to Base64 string
  - Why Base64? WebSocket supports text/binary, Base64 ‡∏á‡πà‡∏≤‡∏¢‡∏Å‡∏ß‡πà‡∏≤
      ‚Üì
[WebSocket Send]
  - Type: 'input_audio_buffer.append'
  - Audio: "base64_encoded_pcm_data"
```

### 2. Go Implementation Details

#### WebSocket Libraries

```bash
# ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á dependencies
go get github.com/gorilla/websocket      # WebSocket server
go get github.com/sashabaranov/go-openai # OpenAI client (‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß)
```

#### Backend Service Structure

```
backend/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ openai_service.go           # ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
‚îÇ   ‚îî‚îÄ‚îÄ realtime_service.go         # ‡πÉ‡∏´‡∏°‡πà - WebSocket to OpenAI Realtime
‚îÇ
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îú‚îÄ‚îÄ audio_controller.go         # ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß
‚îÇ   ‚îî‚îÄ‚îÄ realtime_controller.go      # ‡πÉ‡∏´‡∏°‡πà - WebSocket endpoint
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ transcription.go            # ‡πÉ‡∏´‡∏°‡πà - Realtime event types
‚îÇ
‚îî‚îÄ‚îÄ routes/
    ‚îî‚îÄ‚îÄ routes.go                   # ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï - ‡πÄ‡∏û‡∏¥‡πà‡∏° WebSocket route
```

### 3. Environment Variables

```env
# ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÉ‡∏ô .env.development

# OpenAI Realtime API
OPENAI_REALTIME_ENDPOINT=wss://api.openai.com/v1/realtime
OPENAI_REALTIME_MODEL=gpt-4o-mini-transcribe  # ‡∏´‡∏£‡∏∑‡∏≠ gpt-4o-transcribe
OPENAI_REALTIME_LANGUAGE=en                   # en, th, auto
OPENAI_REALTIME_VAD_THRESHOLD=0.5             # Voice Activity Detection threshold
OPENAI_REALTIME_SILENCE_MS=500                # Silence duration (ms)
OPENAI_REALTIME_NOISE_REDUCTION=near_field    # near_field, far_field
```

### 4. Security Considerations

```go
// CORS Configuration
app.Use(cors.New(cors.Config{
    AllowOrigins:     "http://localhost:5173",
    AllowMethods:     "GET,POST,PUT,DELETE,OPTIONS",
    AllowHeaders:     "Origin,Content-Type,Accept,Authorization",
    AllowCredentials: true,
    AllowWebSockets:  true,  // ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç!
}))

// API Key ‡πÑ‡∏°‡πà‡∏Ñ‡∏ß‡∏£ expose ‡πÑ‡∏õ‡∏¢‡∏±‡∏á Frontend
// Backend ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡∏Å‡∏•‡∏≤‡∏á‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° OpenAI
```

### 5. Error Handling

| Error Code | Description | Solution |
|-----------|-------------|----------|
| `invalid_api_key` | API key ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á | ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö OPENAI_API_KEY |
| `invalid_audio_format` | Format ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á | ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô PCM16 24kHz |
| `rate_limit_exceeded` | ‡πÄ‡∏Å‡∏¥‡∏ô‡πÇ‡∏Ñ‡∏ß‡∏ï‡πâ‡∏≤ | Retry with exponential backoff |
| `connection_timeout` | WebSocket timeout | Reconnect with exponential backoff |
| `unsupported_language` | ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö | ‡πÉ‡∏ä‡πâ 'auto' ‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡∏†‡∏≤‡∏©‡∏≤ |

---

## Implementation Tasks

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 1: Backend - ‡∏™‡∏£‡πâ‡∏≤‡∏á Realtime Service ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡∏™‡∏£‡πâ‡∏≤‡∏á Go service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ OpenAI Realtime API

**‡πÑ‡∏ü‡∏•‡πå**: `backend/services/realtime_service.go`

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á Dependencies**
```bash
cd backend
go get github.com/gorilla/websocket
```

2. **‡∏™‡∏£‡πâ‡∏≤‡∏á RealtimeService struct**
```go
type RealtimeService struct {
    config        *config.Config
    openaiConn    *websocket.Conn
    mu            sync.Mutex
    sessionID     string
    isConnected   bool
}
```

3. **Implement Connection Methods**
- `ConnectToOpenAI()` - ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á OpenAI Realtime API
- `ConfigureSession()` - ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ session (model, language, VAD)
- `StreamAudio()` - ‡∏™‡πà‡∏á audio chunks ‡πÑ‡∏õ‡∏¢‡∏±‡∏á OpenAI
- `ReceiveTranscription()` - ‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ñ‡∏≠‡∏î‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏≤‡∏Å OpenAI
- `Close()` - ‡∏õ‡∏¥‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠

4. **Event Handling**
- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ events ‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡∏à‡∏≤‡∏Å OpenAI (partial, final, error)
- Implement retry logic ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Ç‡∏≤‡∏î

**Unit Test**: `backend/test/realtime/service_test.go`
```bash
go test -v ./test/realtime/
```

---

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 2: Backend - ‡∏™‡∏£‡πâ‡∏≤‡∏á WebSocket Controller ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡∏™‡∏£‡πâ‡∏≤‡∏á WebSocket endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Frontend

**‡πÑ‡∏ü‡∏•‡πå**: `backend/controllers/realtime_controller.go`

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **‡∏™‡∏£‡πâ‡∏≤‡∏á RealtimeController**
```go
type RealtimeController struct {
    realtimeService *services.RealtimeService
    upgrader        websocket.Upgrader
}
```

2. **Implement WebSocket Handler**
- `HandleRealtimeTranscription(c *fiber.Ctx)` - ‡∏≠‡∏±‡∏û‡πÄ‡∏Å‡∏£‡∏î HTTP ‚Üí WebSocket
- ‡∏≠‡πà‡∏≤‡∏ô audio chunks ‡∏à‡∏≤‡∏Å client
- ‡∏™‡πà‡∏á‡∏ï‡πà‡∏≠‡πÑ‡∏õ‡∏¢‡∏±‡∏á RealtimeService
- Forward transcription results ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏õ‡∏¢‡∏±‡∏á client

3. **Connection Management**
- ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏≤‡∏¢ WebSocket connections ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
- Cleanup ‡πÄ‡∏°‡∏∑‡πà‡∏≠ client disconnect
- Implement heartbeat/ping-pong

**API Endpoint**:
```
WS /ws/realtime/transcribe
```

---

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 3: Backend - ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï Config ‡πÅ‡∏•‡∏∞ Routes ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡πÄ‡∏û‡∏¥‡πà‡∏° configuration ‡πÅ‡∏•‡∏∞ routing

**‡πÑ‡∏ü‡∏•‡πå**:
- `backend/config/config.go`
- `backend/routes/routes.go`

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï Config struct** (config.go)
```go
type Config struct {
    // ... existing fields ...

    // OpenAI Realtime
    OpenAIRealtimeEndpoint    string
    OpenAIRealtimeModel       string
    OpenAIRealtimeLanguage    string
    OpenAIRealtimeVADThreshold float64
    OpenAIRealtimeSilenceMs   int
    OpenAIRealtimeNoiseReduction string
}
```

2. **‡πÄ‡∏û‡∏¥‡πà‡∏° WebSocket Route** (routes.go)
```go
func SetupRoutes(app *fiber.App, controllers *Controllers) {
    // ... existing routes ...

    // WebSocket Realtime Transcription
    app.Get("/ws/realtime/transcribe",
        controllers.Realtime.HandleRealtimeTranscription)
}
```

---

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 4: Frontend - Audio Capture Component üé§ ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡∏™‡∏£‡πâ‡∏≤‡∏á Vue component ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏á‡∏ú‡πà‡∏≤‡∏ô WebSocket

**‡πÑ‡∏ü‡∏•‡πå**: `frontend/src/components/audio/RealtimeRecorder.vue`

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **‡∏™‡∏£‡πâ‡∏≤‡∏á Component Template**
```vue
<template>
  <div class="realtime-recorder">
    <button @click="startRecording" :disabled="isRecording">
      üé§ Start Recording
    </button>
    <button @click="stopRecording" :disabled="!isRecording">
      ‚èπÔ∏è Stop
    </button>

    <div class="transcript">
      <div v-for="item in transcripts" :key="item.id">
        <p :class="{ partial: !item.isFinal }">
          {{ item.text }}
        </p>
      </div>
    </div>
  </div>
</template>
```

2. **Implement Audio Capture**
- ‡πÉ‡∏ä‡πâ `navigator.mediaDevices.getUserMedia()`
- ‡∏™‡∏£‡πâ‡∏≤‡∏á `AudioContext` ‡∏ó‡∏µ‡πà 24kHz
- Implement `ScriptProcessor` ‡∏´‡∏£‡∏∑‡∏≠ `AudioWorklet`
- Convert Float32 ‚Üí Int16 ‚Üí Base64

3. **WebSocket Integration**
- ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö `ws://localhost:3000/ws/realtime/transcribe`
- ‡∏™‡πà‡∏á audio chunks ‡πÅ‡∏ö‡∏ö streaming
- ‡∏£‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• partial/final transcripts

4. **State Management**
```javascript
const state = reactive({
  isRecording: false,
  isConnected: false,
  transcripts: [],
  ws: null,
  audioContext: null,
  mediaStream: null
});
```

---

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 5: Frontend - Realtime Service/Composable üì° ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡∏™‡∏£‡πâ‡∏≤‡∏á reusable service ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö WebSocket communication

**‡πÑ‡∏ü‡∏•‡πå**: `frontend/src/composables/useRealtimeTranscription.js`

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **‡∏™‡∏£‡πâ‡∏≤‡∏á Composable**
```javascript
export function useRealtimeTranscription() {
  const ws = ref(null);
  const transcripts = ref([]);
  const isConnected = ref(false);

  const connect = () => {
    ws.value = new WebSocket('ws://localhost:3000/ws/realtime/transcribe');
    // ...
  };

  const sendAudio = (audioData) => {
    if (ws.value && isConnected.value) {
      ws.value.send(JSON.stringify({
        type: 'audio_chunk',
        data: audioData  // Base64
      }));
    }
  };

  const disconnect = () => {
    ws.value?.close();
  };

  return { connect, sendAudio, disconnect, transcripts, isConnected };
}
```

2. **Event Handling**
- `onOpen`: ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ isConnected = true
- `onMessage`: ‡πÅ‡∏¢‡∏Å partial/final transcripts
- `onError`: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ error ‡πÅ‡∏•‡∏∞ reconnect
- `onClose`: cleanup ‡πÅ‡∏•‡∏∞ reconnect logic

---

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 6: Integration Testing üß™ ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö end-to-end flow

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **Unit Tests** (Go)
```bash
# Test RealtimeService
go test -v ./services/realtime_service_test.go

# Test RealtimeController
go test -v ./controllers/realtime_controller_test.go
```

2. **Frontend Unit Tests** (Vue)
```bash
# Test RealtimeRecorder component
npm run test:unit

# Test useRealtimeTranscription composable
npm run test:unit -- RealtimeRecorder
```

3. **Integration Test**
- ‡πÄ‡∏õ‡∏¥‡∏î backend: `go run main.go`
- ‡πÄ‡∏õ‡∏¥‡∏î frontend: `npm run dev`
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏£‡∏±‡∏ö transcription

4. **Performance Testing**
- ‡∏ß‡∏±‡∏î latency (time to first partial transcript)
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏´‡∏•‡∏≤‡∏¢ clients ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
- ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£ reconnect

---

### ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 7: Documentation ‡πÅ‡∏•‡∏∞ Deployment ‚úÖ ‚è≥

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡πÅ‡∏•‡∏∞ deploy

**‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô**:

1. **‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£**
- README.md - ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ Realtime API
- API.md - ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ WebSocket endpoints
- TROUBLESHOOTING.md - ‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ‡∏õ‡∏±‡∏ç‡∏´‡∏≤

2. **Environment Setup**
```bash
# Development
cp .env.development.example .env.development
# ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç OPENAI_API_KEY

# Production
cp .env.production.example .env.production
```

3. **Docker Support** (Optional)
```dockerfile
# ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ï Dockerfile ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö WebSocket
# docker-compose.yml ‡πÄ‡∏û‡∏¥‡πà‡∏° environment variables
```

---

## ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå

### Backend Files (New/Modified)

```
backend/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ openai_service.go             # ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ
‚îÇ   ‚îî‚îÄ‚îÄ realtime_service.go           # ‚ú® ‡πÉ‡∏´‡∏°‡πà
‚îÇ
‚îú‚îÄ‚îÄ controllers/
‚îÇ   ‚îú‚îÄ‚îÄ audio_controller.go           # ‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß - ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ
‚îÇ   ‚îî‚îÄ‚îÄ realtime_controller.go        # ‚ú® ‡πÉ‡∏´‡∏°‡πà
‚îÇ
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îî‚îÄ‚îÄ realtime_events.go            # ‚ú® ‡πÉ‡∏´‡∏°‡πà - Event types
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.go                     # üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡πÄ‡∏û‡∏¥‡πà‡∏° Realtime config
‚îÇ
‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îî‚îÄ‚îÄ routes.go                     # üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡πÄ‡∏û‡∏¥‡πà‡∏° WebSocket route
‚îÇ
‚îî‚îÄ‚îÄ test/
    ‚îî‚îÄ‚îÄ realtime/
        ‚îú‚îÄ‚îÄ service_test.go           # ‚ú® ‡πÉ‡∏´‡∏°‡πà
        ‚îî‚îÄ‚îÄ controller_test.go        # ‚ú® ‡πÉ‡∏´‡∏°‡πà
```

### Frontend Files (New/Modified)

```
frontend/src/
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îî‚îÄ‚îÄ audio/
‚îÇ       ‚îî‚îÄ‚îÄ RealtimeRecorder.vue      # ‚ú® ‡πÉ‡∏´‡∏°‡πà
‚îÇ
‚îú‚îÄ‚îÄ composables/
‚îÇ   ‚îî‚îÄ‚îÄ useRealtimeTranscription.js   # ‚ú® ‡πÉ‡∏´‡∏°‡πà
‚îÇ
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ realtimeService.js            # ‚ú® ‡πÉ‡∏´‡∏°‡πà (Optional - ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ composable)
‚îÇ
‚îî‚îÄ‚îÄ views/
    ‚îî‚îÄ‚îÄ RealtimeTranscriptionView.vue # ‚ú® ‡πÉ‡∏´‡∏°‡πà - Demo page
```

### Configuration Files

```
.env.development                       # üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡πÄ‡∏û‡∏¥‡πà‡∏° Realtime vars
.env.production                        # üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡πÄ‡∏û‡∏¥‡πà‡∏° Realtime vars
docker-compose.yml                     # üîß ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç - ‡πÄ‡∏û‡∏¥‡πà‡∏° environment
```

---

## ‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö

### 1. Manual Testing Checklist

**Backend Testing:**
- [ ] WebSocket server ‡∏£‡∏±‡∏ô‡πÑ‡∏î‡πâ
- [ ] ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö OpenAI Realtime API ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
- [ ] ‡∏™‡πà‡∏á audio chunks ‡πÑ‡∏î‡πâ
- [ ] ‡∏£‡∏±‡∏ö partial transcriptions ‡πÑ‡∏î‡πâ
- [ ] ‡∏£‡∏±‡∏ö final transcriptions ‡πÑ‡∏î‡πâ
- [ ] ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ client disconnect ‡πÑ‡∏î‡πâ
- [ ] Retry mechanism ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
- [ ] Error handling ‡∏Ñ‡∏£‡∏ö‡∏ñ‡πâ‡∏ß‡∏ô

**Frontend Testing:**
- [ ] ‡∏Ç‡∏≠ microphone permission ‡πÑ‡∏î‡πâ
- [ ] ‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å mic ‡πÑ‡∏î‡πâ
- [ ] Audio conversion (Float32‚ÜíInt16‚ÜíBase64) ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- [ ] WebSocket connection ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à
- [ ] ‡∏™‡πà‡∏á audio ‡πÑ‡∏î‡πâ‡πÅ‡∏ö‡∏ö streaming
- [ ] ‡πÅ‡∏™‡∏î‡∏á partial transcripts (real-time)
- [ ] ‡πÅ‡∏™‡∏î‡∏á final transcripts
- [ ] UI responsive ‡πÅ‡∏•‡∏∞ smooth
- [ ] Handle errors gracefully
- [ ] Cleanup resources ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î

### 2. Unit Tests

**Go Backend:**
```bash
# Test Realtime Service
go test -v ./services/realtime_service_test.go -run TestConnectToOpenAI
go test -v ./services/realtime_service_test.go -run TestStreamAudio
go test -v ./services/realtime_service_test.go -run TestReceiveTranscription

# Test Controller
go test -v ./controllers/realtime_controller_test.go -run TestWebSocketUpgrade
go test -v ./controllers/realtime_controller_test.go -run TestHandleClientAudio

# Run all tests
go test -v ./...
```

**Vue Frontend:**
```bash
# Test component
npm run test:unit -- RealtimeRecorder.spec.js

# Test composable
npm run test:unit -- useRealtimeTranscription.spec.js

# Coverage report
npm run test:coverage
```

### 3. Integration Test

**Scenario 1: Single User Transcription**
```bash
# 1. Start backend
cd backend && go run main.go

# 2. Start frontend
cd frontend && npm run dev

# 3. Open browser http://localhost:5173
# 4. Navigate to /realtime-transcription
# 5. Click "Start Recording"
# 6. Speak: "Hello, this is a test"
# 7. Verify partial transcripts appear in real-time
# 8. Click "Stop Recording"
# 9. Verify final transcript is correct
```

**Scenario 2: Multiple Users**
```bash
# ‡πÄ‡∏õ‡∏¥‡∏î‡∏´‡∏•‡∏≤‡∏¢ browser tabs/windows
# ‡∏ó‡∏î‡∏™‡∏≠‡∏ö concurrent connections (3-5 users)
# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ cross-talk ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á users
```

**Scenario 3: Connection Issues**
```bash
# 1. Start recording
# 2. ‡∏õ‡∏¥‡∏î backend ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å
# 3. ‡πÄ‡∏õ‡∏¥‡∏î backend ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤
# 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ reconnect ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥
# 5. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ transcription ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡πÑ‡∏î‡πâ
```

### 4. Performance Testing

```bash
# ‡πÉ‡∏ä‡πâ tool ‡πÄ‡∏ä‡πà‡∏ô k6 ‡∏´‡∏£‡∏∑‡∏≠ Artillery
# Load test: 10-50 concurrent WebSocket connections
k6 run load-test-websocket.js

# Expected Results:
# - Latency: < 1s (95th percentile)
# - Connection success rate: > 99%
# - No memory leaks
# - CPU usage stable
```

---

## ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á

### Official Documentation

- [OpenAI Realtime API Documentation](https://platform.openai.com/docs/guides/realtime)
- [OpenAI Audio API (Whisper)](https://platform.openai.com/docs/guides/speech-to-text)
- [WebSocket RFC 6455](https://datatracker.ietf.org/doc/html/rfc6455)
- [MDN Web Audio API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API)

### Libraries & Tools

- [Gorilla WebSocket (Go)](https://github.com/gorilla/websocket)
- [go-openai (Go SDK)](https://github.com/sashabaranov/go-openai)
- [MediaRecorder API (Browser)](https://developer.mozilla.org/en-US/docs/Web/API/MediaRecorder)
- [Vue.js Composables](https://vuejs.org/guide/reusability/composables.html)

### Pricing (as of 2025)

| Model | Price | Input | Note |
|-------|-------|-------|------|
| gpt-4o-transcribe | $0.10/min | Audio stream | High accuracy |
| gpt-4o-mini-transcribe | $0.01/min | Audio stream | Fast, lower cost |
| whisper-1 (Batch) | $0.006/min | Audio file | Non-realtime |

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì:**
- Meeting 1 ‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á (60 ‡∏ô‡∏≤‡∏ó‡∏µ)
  - gpt-4o-transcribe: $6.00
  - gpt-4o-mini-transcribe: $0.60
  - whisper-1 (Batch): $0.36

### Related Documents

- [WHISPER_START.md](./WHISPER_START.md) - Whisper.cpp Implementation (Tasks 1-2 ‚úÖ)
- Backend API documentation: `/backend/README.md`
- Frontend components: `/frontend/src/components/audio/README.md`

---

## ‡∏™‡∏£‡∏∏‡∏õ

### ‚úÖ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡πÅ‡∏•‡πâ‡∏ß (Current State)

1. **OpenAI Whisper API Integration**
   - File: `backend/services/openai_service.go`
   - Endpoint: `POST /api/audio/transcribe`
   - ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö batch transcription

2. **Whisper.cpp Local Implementation**
   - Binary: `backend/whisper/binary/`
   - Config: `.env.development` (WHISPER_* variables)
   - Tests: `backend/test/sst-whisper/`

3. **Frontend Audio Recording**
   - Component: `frontend/src/components/chat/ChatInput.vue` (‡∏°‡∏µ audio recorder)
   - ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ realtime streaming

### üéØ ‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á (To Be Implemented)

1. **Backend Realtime Service** (`backend/services/realtime_service.go`)
2. **Backend Realtime Controller** (`backend/controllers/realtime_controller.go`)
3. **Frontend Realtime Recorder** (`frontend/src/components/audio/RealtimeRecorder.vue`)
4. **Frontend Composable** (`frontend/src/composables/useRealtimeTranscription.js`)
5. **Integration Tests**
6. **Documentation**

### üìä Expected Timeline

| Task | Estimated Time | Priority |
|------|---------------|----------|
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 1: Backend Service | 4-6 hours | üî¥ High |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 2: Backend Controller | 3-4 hours | üî¥ High |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 3: Config & Routes | 1-2 hours | üî¥ High |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 4: Frontend Component | 4-5 hours | üü° Medium |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 5: Frontend Composable | 2-3 hours | üü° Medium |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 6: Integration Tests | 3-4 hours | üü¢ Low |
| ‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà 7: Documentation | 2-3 hours | üü¢ Low |
| **Total** | **19-27 hours** | |

---

**Created**: 2025-11-10
**Last Updated**: 2025-11-10
**Status**: üìù Planning Phase - Ready for Implementation
