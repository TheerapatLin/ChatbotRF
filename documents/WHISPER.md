# Whisper.cpp - à¸„à¸¹à¹ˆà¸¡à¸·à¸­à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¹à¸¥à¸°à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡

## ğŸ“‹ à¸ªà¸²à¸£à¸šà¸±à¸
1. [à¸ à¸²à¸à¸£à¸§à¸¡](#à¸ à¸²à¸à¸£à¸§à¸¡)
2. [à¸ à¸²à¸©à¸²à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰](#à¸ à¸²à¸©à¸²à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰)
3. [à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ](#à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ)
4. [à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¸«à¸¥à¸±à¸](#à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¸«à¸¥à¸±à¸)
5. [à¸£à¸°à¸šà¸š Build](#à¸£à¸°à¸šà¸š-build)
6. [à¹„à¸Ÿà¸¥à¹Œà¸ªà¸³à¸„à¸±à¸à¹à¸¥à¸°à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ](#à¹„à¸Ÿà¸¥à¹Œà¸ªà¸³à¸„à¸±à¸à¹à¸¥à¸°à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ)
7. [Go Bindings](#go-bindings)
8. [GGML Framework](#ggml-framework)
9. [à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ Whisper](#à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡-whisper)
10. [Hardware Acceleration](#hardware-acceleration)
11. [à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™](#à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™)

---

## à¸ à¸²à¸à¸£à¸§à¸¡

**Whisper.cpp** à¸„à¸·à¸­à¸à¸²à¸£ implement à¹‚à¸¡à¹€à¸”à¸¥ Whisper à¸‚à¸­à¸‡ OpenAI à¸”à¹‰à¸§à¸¢à¸ à¸²à¸©à¸² C/C++ à¹€à¸à¸·à¹ˆà¸­à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸ªà¸¹à¸‡à¸ªà¸¸à¸” à¹‚à¸”à¸¢à¸­à¸­à¸à¹à¸šà¸šà¹ƒà¸«à¹‰:
- **Zero dependencies** - à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸¶à¹ˆà¸‡à¸à¸² library à¸ à¸²à¸¢à¸™à¸­à¸
- **Cross-platform** - à¸£à¸­à¸‡à¸£à¸±à¸š Linux, macOS, Windows, iOS, Android, WebAssembly
- **High performance** - optimized à¸ªà¸³à¸«à¸£à¸±à¸š CPU à¹à¸¥à¸° GPU à¸«à¸¥à¸²à¸¢à¸£à¸¸à¹ˆà¸™
- **Memory efficient** - à¸£à¸­à¸‡à¸£à¸±à¸š quantization à¸¥à¸”à¸‚à¸™à¸²à¸”à¹‚à¸¡à¹€à¸”à¸¥ 2-4 à¹€à¸—à¹ˆà¸²
- **Easy integration** - à¸¡à¸µ bindings à¸ªà¸³à¸«à¸£à¸±à¸šà¸«à¸¥à¸²à¸¢à¸ à¸²à¸©à¸² (Go, Java, JavaScript, Ruby)

**Location**: `backend/whisper/whisper-source/`

---

## à¸ à¸²à¸©à¸²à¹‚à¸›à¸£à¹à¸à¸£à¸¡à¸—à¸µà¹ˆà¹ƒà¸Šà¹‰

### 1. **C/C++ (à¸«à¸¥à¸±à¸)**
- **C++11**: Core library implementation
  - [whisper.cpp](backend/whisper/whisper-source/src/whisper.cpp) (~339 KB) - Implementation à¸«à¸¥à¸±à¸
  - [whisper-arch.h](backend/whisper/whisper-source/src/whisper-arch.h) - Model architecture definitions
- **C**: GGML tensor operations
  - [ggml.c](backend/whisper/whisper-source/ggml/src/ggml.c) (243 KB) - Tensor operations
  - [ggml-quants.c](backend/whisper/whisper-source/ggml/src/ggml-quants.c) (223 KB) - Quantization
- **Assembly (ASM)**: SIMD optimizations (AVX, NEON, VSX)

### 2. **Go**
- **Location**: [bindings/go/](backend/whisper/whisper-source/bindings/go/)
- **Purpose**: CGO bindings à¸ªà¸³à¸«à¸£à¸±à¸š integration à¸à¸±à¸š Go projects
- **Features**: Thread-safe, static linking, CUDA support

### 3. **JavaScript**
- **Location**: [bindings/javascript/](backend/whisper/whisper-source/bindings/javascript/)
- **Purpose**: WebAssembly bindings à¸œà¹ˆà¸²à¸™ Emscripten
- **Use case**: Web browsers, Node.js

### 4. **Java**
- **Location**: [bindings/java/](backend/whisper/whisper-source/bindings/java/)
- **Purpose**: JNI bindings à¸ªà¸³à¸«à¸£à¸±à¸š Android/JVM
- **Build**: Gradle

### 5. **Ruby**
- **Location**: [bindings/ruby/](backend/whisper/whisper-source/bindings/ruby/)
- **Purpose**: C extension bindings
- **Build**: Rake

### 6. **Python**
- **Location**: [models/](backend/whisper/whisper-source/models/)
- **Purpose**: Model conversion scripts (PyTorch â†’ GGML)
- **Files**: `convert-pt-to-ggml.py`, `download-ggml-model.py`

### 7. **Objective-C/Swift**
- **Location**: [examples/whisper.objc/](backend/whisper/whisper-source/examples/whisper.objc/), [examples/whisper.swiftui/](backend/whisper/whisper-source/examples/whisper.swiftui/)
- **Purpose**: iOS/macOS applications
- **Features**: Core ML integration

### 8. **Shell/Bash**
- **Purpose**: Build scripts, model download utilities
- **Files**: `build-xcframework.sh`, download scripts

---

## à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸Ÿà¸¥à¹€à¸”à¸­à¸£à¹Œ

```
backend/whisper/whisper-source/
â”œâ”€â”€ CMakeLists.txt              # CMake build configuration
â”œâ”€â”€ Makefile                    # Simple build system
â”œâ”€â”€ README.md                   # Documentation
â”œâ”€â”€ LICENSE                     # MIT License
â”œâ”€â”€ AUTHORS                     # Contributors
â”‚
â”œâ”€â”€ include/                    # Public API headers
â”‚   â””â”€â”€ whisper.h               # Main C API (35 KB)
â”‚
â”œâ”€â”€ src/                        # Core implementation
â”‚   â”œâ”€â”€ whisper.cpp             # Main implementation (339 KB)
â”‚   â””â”€â”€ whisper-arch.h          # Architecture definitions
â”‚
â”œâ”€â”€ ggml/                       # GGML tensor library
â”‚   â”œâ”€â”€ include/                # GGML headers
â”‚   â”‚   â”œâ”€â”€ ggml.h              # Tensor API (100 KB)
â”‚   â”‚   â”œâ”€â”€ ggml-backend.h      # Backend abstraction
â”‚   â”‚   â”œâ”€â”€ ggml-cpu.h          # CPU backend
â”‚   â”‚   â”œâ”€â”€ ggml-cuda.h         # NVIDIA CUDA
â”‚   â”‚   â”œâ”€â”€ ggml-metal.h        # Apple Metal
â”‚   â”‚   â”œâ”€â”€ ggml-vulkan.h       # Vulkan
â”‚   â”‚   â””â”€â”€ gguf.h              # GGUF file format
â”‚   â”œâ”€â”€ src/                    # GGML implementation
â”‚   â”‚   â”œâ”€â”€ ggml.c              # Core tensor ops (243 KB)
â”‚   â”‚   â”œâ”€â”€ ggml-quants.c       # Quantization (223 KB)
â”‚   â”‚   â”œâ”€â”€ ggml-cpu/           # CPU backend
â”‚   â”‚   â”œâ”€â”€ ggml-cuda/          # CUDA backend
â”‚   â”‚   â”œâ”€â”€ ggml-metal/         # Metal backend
â”‚   â”‚   â”œâ”€â”€ ggml-vulkan/        # Vulkan backend
â”‚   â”‚   â”œâ”€â”€ ggml-opencl/        # OpenCL backend
â”‚   â”‚   â”œâ”€â”€ ggml-hexagon/       # Qualcomm Hexagon
â”‚   â”‚   â”œâ”€â”€ ggml-cann/          # Huawei CANN (Ascend NPU)
â”‚   â”‚   â””â”€â”€ ggml-sycl/          # Intel SYCL
â”‚   â””â”€â”€ CMakeLists.txt
â”‚
â”œâ”€â”€ bindings/                   # Language bindings
â”‚   â”œâ”€â”€ go/                     # Go bindings
â”‚   â”‚   â”œâ”€â”€ whisper.go          # CGO interface
â”‚   â”‚   â”œâ”€â”€ params.go           # Parameters
â”‚   â”‚   â”œâ”€â”€ pkg/whisper/        # High-level Go API
â”‚   â”‚   â”‚   â”œâ”€â”€ context.go      # Context management
â”‚   â”‚   â”‚   â”œâ”€â”€ model.go        # Model loading
â”‚   â”‚   â”‚   â”œâ”€â”€ interface.go    # Interfaces
â”‚   â”‚   â”‚   â””â”€â”€ consts.go       # Constants
â”‚   â”‚   â”œâ”€â”€ examples/
â”‚   â”‚   â”‚   â”œâ”€â”€ go-whisper/     # CLI example
â”‚   â”‚   â”‚   â””â”€â”€ go-model-download/
â”‚   â”‚   â”œâ”€â”€ Makefile
â”‚   â”‚   â””â”€â”€ go.mod
â”‚   â”œâ”€â”€ java/                   # Java/Android bindings
â”‚   â”œâ”€â”€ javascript/             # WebAssembly bindings
â”‚   â””â”€â”€ ruby/                   # Ruby bindings
â”‚
â”œâ”€â”€ examples/                   # Example applications
â”‚   â”œâ”€â”€ cli/                    # Command-line tool (cli.cpp - 62 KB)
â”‚   â”œâ”€â”€ stream/                 # Real-time transcription
â”‚   â”œâ”€â”€ server/                 # HTTP REST API
â”‚   â”œâ”€â”€ command/                # Voice commands
â”‚   â”œâ”€â”€ bench/                  # Benchmarking
â”‚   â”œâ”€â”€ quantize/               # Model quantization
â”‚   â”œâ”€â”€ whisper.wasm/           # WebAssembly
â”‚   â”œâ”€â”€ whisper.android/        # Android app
â”‚   â”œâ”€â”€ whisper.objc/           # iOS (Objective-C)
â”‚   â”œâ”€â”€ whisper.swiftui/        # iOS/macOS (SwiftUI)
â”‚   â”œâ”€â”€ talk-llama/             # Voice chat with LLaMA
â”‚   â”œâ”€â”€ common.cpp/h            # Shared utilities
â”‚   â”œâ”€â”€ common-whisper.cpp/h    # Whisper helpers
â”‚   â””â”€â”€ common-sdl.cpp/h        # SDL audio capture
â”‚
â”œâ”€â”€ models/                     # Model management
â”‚   â”œâ”€â”€ download-ggml-model.py  # Model downloader
â”‚   â”œâ”€â”€ convert-pt-to-ggml.py   # PyTorch â†’ GGML converter
â”‚   â””â”€â”€ generate-coreml-model.sh # Core ML converter
â”‚
â”œâ”€â”€ samples/                    # Audio samples for testing
â”‚   â””â”€â”€ jfk.wav                 # Example audio
â”‚
â”œâ”€â”€ tests/                      # Test suite
â”œâ”€â”€ scripts/                    # Utility scripts
â”œâ”€â”€ grammars/                   # Grammar files
â””â”€â”€ ci/                         # CI/CD configurations
```

---

## à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡à¸«à¸¥à¸±à¸

### Whisper Model Architecture

Whisper à¹ƒà¸Šà¹‰à¸ªà¸–à¸²à¸›à¸±à¸•à¸¢à¸à¸£à¸£à¸¡ **Encoder-Decoder Transformer**:

```
Audio Input (16 kHz, mono)
        â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Mel Spectrogram â”‚  â† 80-channel mel filterbank
   â”‚  Extraction      â”‚    FFT: 400 samples
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    Hop: 160 samples
        â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     ENCODER     â”‚
   â”‚  (Transformer)  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ â€¢ Conv1D layers â”‚  â† Feature extraction
   â”‚ â€¢ Positional    â”‚  â† Position encoding
   â”‚   embeddings    â”‚
   â”‚ â€¢ Multi-head    â”‚  â† Self-attention (Ã—N layers)
   â”‚   attention     â”‚
   â”‚ â€¢ MLP blocks    â”‚  â† Feed-forward
   â”‚ â€¢ Layer norm    â”‚  â† Normalization
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“ (audio embeddings)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚     DECODER     â”‚
   â”‚  (Transformer)  â”‚
   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
   â”‚ â€¢ Token         â”‚  â† Text embeddings
   â”‚   embeddings    â”‚
   â”‚ â€¢ Positional    â”‚  â† Position encoding
   â”‚   embeddings    â”‚
   â”‚ â€¢ Self-attentionâ”‚  â† Attends to previous tokens
   â”‚ â€¢ Cross-attentionâ”‚ â† Attends to encoder output
   â”‚ â€¢ MLP blocks    â”‚  â† Feed-forward
   â”‚ â€¢ Layer norm    â”‚  â† Normalization
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
  Token Prediction (greedy/beam search)
        â†“
   Text Output + Timestamps
```

### Encoder Components

à¸ˆà¸²à¸ [whisper-arch.h](backend/whisper/whisper-source/src/whisper-arch.h):

```cpp
// Encoder tensors
encoder.positional_embedding    // Position encoding
encoder.conv1.weight            // Conv layer 1 (feature extraction)
encoder.conv1.bias
encoder.conv2.weight            // Conv layer 2
encoder.conv2.bias

// Per-layer (repeated N times)
encoder.blocks.{i}.attn_ln.weight      // Layer norm (attention)
encoder.blocks.{i}.attn_ln.bias
encoder.blocks.{i}.attn.query.weight   // Multi-head attention Q
encoder.blocks.{i}.attn.query.bias
encoder.blocks.{i}.attn.key.weight     // Multi-head attention K
encoder.blocks.{i}.attn.value.weight   // Multi-head attention V
encoder.blocks.{i}.attn.value.bias
encoder.blocks.{i}.attn.out.weight     // Attention output projection
encoder.blocks.{i}.attn.out.bias

encoder.blocks.{i}.mlp_ln.weight       // Layer norm (MLP)
encoder.blocks.{i}.mlp_ln.bias
encoder.blocks.{i}.mlp.0.weight        // MLP layer 1
encoder.blocks.{i}.mlp.0.bias
encoder.blocks.{i}.mlp.2.weight        // MLP layer 2
encoder.blocks.{i}.mlp.2.bias

encoder.ln_post.weight          // Final layer norm
encoder.ln_post.bias
```

### Decoder Components

```cpp
// Decoder tensors
decoder.token_embedding.weight   // Token vocabulary embeddings
decoder.positional_embedding     // Position encoding

// Per-layer (repeated N times)
decoder.blocks.{i}.attn_ln.weight       // Layer norm (self-attention)
decoder.blocks.{i}.attn_ln.bias
decoder.blocks.{i}.attn.query.weight    // Self-attention Q
decoder.blocks.{i}.attn.query.bias
decoder.blocks.{i}.attn.key.weight      // Self-attention K
decoder.blocks.{i}.attn.value.weight    // Self-attention V
decoder.blocks.{i}.attn.value.bias
decoder.blocks.{i}.attn.out.weight      // Self-attention output
decoder.blocks.{i}.attn.out.bias

decoder.blocks.{i}.cross_attn_ln.weight // Layer norm (cross-attention)
decoder.blocks.{i}.cross_attn_ln.bias
decoder.blocks.{i}.cross_attn.query.weight  // Cross-attention Q
decoder.blocks.{i}.cross_attn.query.bias
decoder.blocks.{i}.cross_attn.key.weight    // Cross-attention K (to encoder)
decoder.blocks.{i}.cross_attn.value.weight  // Cross-attention V (to encoder)
decoder.blocks.{i}.cross_attn.value.bias
decoder.blocks.{i}.cross_attn.out.weight    // Cross-attention output
decoder.blocks.{i}.cross_attn.out.bias

decoder.blocks.{i}.mlp_ln.weight        // Layer norm (MLP)
decoder.blocks.{i}.mlp_ln.bias
decoder.blocks.{i}.mlp.0.weight         // MLP layer 1
decoder.blocks.{i}.mlp.0.bias
decoder.blocks.{i}.mlp.2.weight         // MLP layer 2
decoder.blocks.{i}.mlp.2.bias

decoder.ln.weight                // Final layer norm
decoder.ln.bias
```

### Model Sizes

| Model | Parameters | English-only | Multilingual | Memory (FP16) | Memory (Q5_0) |
|-------|-----------|--------------|--------------|---------------|---------------|
| tiny  | 39 M      | 75 MB        | 75 MB        | 150 MB        | 45 MB         |
| base  | 74 M      | 142 MB       | 142 MB       | 280 MB        | 85 MB         |
| small | 244 M     | 466 MB       | 466 MB       | 930 MB        | 280 MB        |
| medium| 769 M     | 1.5 GB       | 1.5 GB       | 3.0 GB        | 900 MB        |
| large | 1550 M    | -            | 2.9 GB       | 5.8 GB        | 1.7 GB        |
| large-v3 | 1550 M | -            | 2.9 GB       | 5.8 GB        | 1.7 GB        |

**Quantization** à¸¥à¸”à¸‚à¸™à¸²à¸”à¹‚à¸¡à¹€à¸”à¸¥à¸¥à¸‡à¹„à¸”à¹‰ ~3 à¹€à¸—à¹ˆà¸² à¹‚à¸”à¸¢à¸¢à¸±à¸‡à¸„à¸‡à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³à¹ƒà¸à¸¥à¹‰à¹€à¸„à¸µà¸¢à¸‡à¸à¸±à¸™

---

## à¸£à¸°à¸šà¸š Build

### CMake Build System

[CMakeLists.txt](backend/whisper/whisper-source/CMakeLists.txt) à¸à¸³à¸«à¸™à¸”:

```cmake
cmake_minimum_required(VERSION 3.5)
project(whisper VERSION 1.8.2)
```

#### Build Options

```bash
# Core options
-DWHISPER_BUILD_EXAMPLES=ON     # Build example programs
-DWHISPER_BUILD_TESTS=ON        # Build test suite
-DWHISPER_BUILD_SERVER=ON       # Build HTTP server

# Audio/Video
-DWHISPER_FFMPEG=ON             # Enable FFmpeg support (Linux)
-DWHISPER_SDL2=ON               # Enable SDL2 audio input

# Hardware acceleration
-DGGML_CUDA=ON                  # NVIDIA CUDA support
-DGGML_METAL=ON                 # Apple Metal (macOS)
-DGGML_VULKAN=ON                # Vulkan GPU support
-DGGML_BLAS=ON                  # BLAS acceleration (OpenBLAS, Intel MKL)
-DGGML_OPENBLAS=ON              # OpenBLAS specifically
-DGGML_RPC=ON                   # RPC backend support

# Apple-specific
-DWHISPER_COREML=ON             # Apple Core ML (iOS/macOS)
-DWHISPER_COREML_ALLOW_FALLBACK=ON

# Intel-specific
-DWHISPER_OPENVINO=ON           # Intel OpenVINO

# CPU optimizations
-DGGML_AVX=ON                   # AVX instructions
-DGGML_AVX2=ON                  # AVX2 instructions
-DGGML_FMA=ON                   # FMA instructions
-DGGML_F16C=ON                  # F16C instructions
```

#### Build Commands

```bash
# Standard build
mkdir build
cd build
cmake ..
cmake --build . --config Release

# With CUDA support
cmake -DGGML_CUDA=ON ..
cmake --build . --config Release

# With Metal support (macOS)
cmake -DGGML_METAL=ON ..
cmake --build . --config Release

# Cross-compile for Windows (from Linux)
cmake -DCMAKE_TOOLCHAIN_FILE=cmake/mingw-w64-x86_64.cmake ..
cmake --build . --config Release
```

### Makefile (Simplified Build)

[Makefile](backend/whisper/whisper-source/Makefile) à¸ªà¸³à¸«à¸£à¸±à¸š quick builds:

```bash
# Quick commands
make                    # Build main executable
make clean             # Clean build artifacts
make samples           # Download audio samples

# Model downloads and tests
make tiny.en           # Download tiny.en model
make base.en           # Download base.en model
make small.en          # Download small.en model
make medium.en         # Download medium.en model
make large             # Download large model

# Examples
make stream            # Build streaming example
make command           # Build command recognition
make bench             # Build benchmark tool
make quantize          # Build quantization tool
```

### GGML CMake

[ggml/CMakeLists.txt](backend/whisper/whisper-source/ggml/CMakeLists.txt):

```cmake
project(ggml VERSION 0.9.4)
```

**Modular Backend System**: GGML à¹ƒà¸Šà¹‰à¸£à¸°à¸šà¸š backend à¹à¸šà¸š pluggable à¸—à¸µà¹ˆà¸ªà¸²à¸¡à¸²à¸£à¸–à¹‚à¸«à¸¥à¸”à¹à¸šà¸š dynamic:

```
ggml-base (core library)
    â”œâ”€â”€ ggml-cpu (default backend)
    â”œâ”€â”€ ggml-cuda (NVIDIA GPUs)
    â”œâ”€â”€ ggml-metal (Apple GPUs)
    â”œâ”€â”€ ggml-vulkan (cross-platform GPUs)
    â”œâ”€â”€ ggml-opencl (older GPUs)
    â”œâ”€â”€ ggml-sycl (Intel GPUs)
    â”œâ”€â”€ ggml-hexagon (Qualcomm NPUs)
    â””â”€â”€ ggml-cann (Huawei Ascend NPUs)
```

---

## à¹„à¸Ÿà¸¥à¹Œà¸ªà¸³à¸„à¸±à¸à¹à¸¥à¸°à¸«à¸™à¹‰à¸²à¸—à¸µà¹ˆ

### 1. Core Library Files

#### [include/whisper.h](backend/whisper/whisper-source/include/whisper.h) (35 KB)

**Public C API** - Interface à¸«à¸¥à¸±à¸à¸ªà¸³à¸«à¸£à¸±à¸šà¹ƒà¸Šà¹‰à¸‡à¸²à¸™ Whisper

**Key Constants**:
```c
#define WHISPER_SAMPLE_RATE 16000  // Required audio sample rate
#define WHISPER_N_FFT       400     // FFT size
#define WHISPER_HOP_LENGTH  160     // Hop length
#define WHISPER_CHUNK_SIZE  30      // 30-second chunks
```

**Main Structures**:
```c
struct whisper_context;           // Opaque context handle
typedef int32_t whisper_token;    // Token type

// Transcription parameters
struct whisper_full_params {
    enum whisper_sampling_strategy strategy;  // GREEDY or BEAM_SEARCH

    int n_threads;                // Number of threads
    int n_max_text_ctx;           // Max text context
    int offset_ms;                // Audio offset
    int duration_ms;              // Audio duration

    bool translate;               // Translate to English
    bool no_context;              // No past context
    bool no_timestamps;           // No timestamps
    bool single_segment;          // Single segment mode
    bool print_special;           // Print special tokens
    bool print_progress;          // Print progress
    bool print_realtime;          // Real-time printing
    bool print_timestamps;        // Print timestamps

    const char * language;        // Language code (e.g., "th", "en")
    const char * prompt;          // Initial prompt

    // Callbacks
    whisper_new_segment_callback new_segment_callback;
    whisper_progress_callback progress_callback;
    whisper_encoder_begin_callback encoder_begin_callback;
    // ...
};
```

**Key Functions**:
```c
// Model management
struct whisper_context * whisper_init_from_file(const char * path_model);
void whisper_free(struct whisper_context * ctx);

// Transcription
int whisper_full(
    struct whisper_context * ctx,
    struct whisper_full_params params,
    const float * samples,
    int n_samples
);

// Results
int whisper_full_n_segments(struct whisper_context * ctx);
const char * whisper_full_get_segment_text(struct whisper_context * ctx, int i_segment);
int64_t whisper_full_get_segment_t0(struct whisper_context * ctx, int i_segment);
int64_t whisper_full_get_segment_t1(struct whisper_context * ctx, int i_segment);

// Language detection
int whisper_full_lang_id(struct whisper_context * ctx);
const char * whisper_lang_str(int id);

// Utilities
struct whisper_full_params whisper_full_default_params(
    enum whisper_sampling_strategy strategy
);
int whisper_pcm_to_mel(
    struct whisper_context * ctx,
    const float * samples,
    int n_samples,
    int n_threads
);
```

---

#### [src/whisper.cpp](backend/whisper/whisper-source/src/whisper.cpp) (339 KB)

**Main Implementation** - Core logic à¸‚à¸­à¸‡ Whisper

**Key Components**:

1. **Model Loading**:
```cpp
// Load GGML/GGUF format models
struct whisper_model_loader {
    virtual size_t read(void * ptr, size_t size) = 0;
    virtual void seek(size_t offset, int whence) = 0;
    virtual size_t tell() const = 0;
    virtual size_t size() const = 0;
};

bool whisper_model_load(const std::string & fname, whisper_context & wctx);
```

2. **Audio Preprocessing**:
```cpp
// Convert PCM to mel spectrogram
bool whisper_pcm_to_mel_phase_vocoder(
    struct whisper_context * ctx,
    const float * samples,
    int n_samples,
    int n_threads
);

// Mel filterbank computation
void whisper_build_mel_filters();
```

3. **Encoder Inference**:
```cpp
// Run encoder on mel spectrogram
bool whisper_encode_internal(
    whisper_context & wctx,
    whisper_state & wstate,
    const int mel_offset,
    const int n_threads
);
```

4. **Decoder Inference**:
```cpp
// Run decoder to generate tokens
bool whisper_decode_internal(
    whisper_context & wctx,
    whisper_state & wstate,
    const whisper_token * tokens,
    const int n_tokens,
    const int n_past,
    const int n_threads
);
```

5. **Beam Search**:
```cpp
struct whisper_beam_candidate {
    int i_segment;
    std::vector<whisper_token> tokens;
    double p;  // Cumulative probability
    // ...
};

void whisper_beam_search(
    whisper_context & wctx,
    whisper_state & wstate,
    // ...
);
```

6. **Token Sampling**:
```cpp
whisper_token whisper_sample_token(
    whisper_context & wctx,
    whisper_state & wstate,
    whisper_sampling_strategy strategy
);
```

**Memory Management**:
```cpp
// Zero runtime allocation philosophy
// All memory allocated upfront in context creation
struct whisper_context {
    struct ggml_context * ctx_data;     // Model data
    struct ggml_context * ctx_work;     // Working memory
    struct ggml_context * ctx_work_enc; // Encoder work
    struct ggml_context * ctx_work_dec; // Decoder work

    // Pre-allocated buffers
    std::vector<uint8_t> buf_compute;   // Computation buffer
    std::vector<uint8_t> buf_scratch[4]; // Scratch buffers
    // ...
};
```

---

#### [src/whisper-arch.h](backend/whisper/whisper-source/src/whisper-arch.h)

**Architecture Definitions** - à¸à¸³à¸«à¸™à¸”à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡à¸‚à¸­à¸‡ tensors

```cpp
// Tensor naming conventions
static const std::map<e_model, whisper_vocab> g_vocab = {
    { MODEL_TINY,   { "gpt2", 51864 } },
    { MODEL_BASE,   { "gpt2", 51864 } },
    { MODEL_SMALL,  { "gpt2", 51864 } },
    { MODEL_MEDIUM, { "gpt2", 51864 } },
    { MODEL_LARGE,  { "gpt2", 51864 } },
};

// Model configurations
struct whisper_hparams {
    int32_t n_vocab;        // Vocabulary size
    int32_t n_audio_ctx;    // Audio context length
    int32_t n_audio_state;  // Audio embedding dimension
    int32_t n_audio_head;   // Audio attention heads
    int32_t n_audio_layer;  // Audio encoder layers
    int32_t n_text_ctx;     // Text context length
    int32_t n_text_state;   // Text embedding dimension
    int32_t n_text_head;    // Text attention heads
    int32_t n_text_layer;   // Text decoder layers
    int32_t n_mels;         // Mel channels (80)
    int32_t ftype;          // File type (quantization)
};
```

---

### 2. GGML Files

#### [ggml/include/ggml.h](backend/whisper/whisper-source/ggml/include/ggml.h) (100 KB)

**Tensor Library API**

**Core Concepts**:
```c
// Tensor structure
struct ggml_tensor {
    enum ggml_type type;      // Data type (FP32, FP16, Q4_0, ...)

    int64_t ne[GGML_MAX_DIMS]; // Number of elements per dimension
    size_t  nb[GGML_MAX_DIMS]; // Stride in bytes per dimension

    enum ggml_op op;           // Operation type

    struct ggml_tensor * src[GGML_MAX_SRC]; // Source tensors

    void * data;               // Tensor data
    char name[GGML_MAX_NAME];  // Tensor name

    void * extra;              // Extra data
};

// Context (memory arena)
struct ggml_context;

// Computation graph
struct ggml_cgraph {
    int n_nodes;
    int n_leafs;
    struct ggml_tensor ** nodes;
    struct ggml_tensor ** grads;
    struct ggml_tensor ** leafs;
    // ...
};
```

**Tensor Operations**:
```c
// Basic operations
struct ggml_tensor * ggml_add(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b);
struct ggml_tensor * ggml_mul(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b);
struct ggml_tensor * ggml_div(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b);

// Matrix operations
struct ggml_tensor * ggml_mul_mat(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b);
struct ggml_tensor * ggml_matmul(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b);

// Neural network operations
struct ggml_tensor * ggml_conv_1d(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b, int s0, int p0, int d0);
struct ggml_tensor * ggml_conv_2d(struct ggml_context * ctx, struct ggml_tensor * a, struct ggml_tensor * b, int s0, int s1, int p0, int p1, int d0, int d1);

// Attention
struct ggml_tensor * ggml_flash_attn(struct ggml_context * ctx, struct ggml_tensor * q, struct ggml_tensor * k, struct ggml_tensor * v, bool masked);

// Activation functions
struct ggml_tensor * ggml_gelu(struct ggml_context * ctx, struct ggml_tensor * a);
struct ggml_tensor * ggml_relu(struct ggml_context * ctx, struct ggml_tensor * a);
struct ggml_tensor * ggml_silu(struct ggml_context * ctx, struct ggml_tensor * a);

// Normalization
struct ggml_tensor * ggml_norm(struct ggml_context * ctx, struct ggml_tensor * a, float eps);
struct ggml_tensor * ggml_rms_norm(struct ggml_context * ctx, struct ggml_tensor * a, float eps);

// Utilities
struct ggml_tensor * ggml_reshape_3d(struct ggml_context * ctx, struct ggml_tensor * a, int64_t ne0, int64_t ne1, int64_t ne2);
struct ggml_tensor * ggml_view_1d(struct ggml_context * ctx, struct ggml_tensor * a, int64_t ne0, size_t offset);
struct ggml_tensor * ggml_permute(struct ggml_context * ctx, struct ggml_tensor * a, int axis0, int axis1, int axis2, int axis3);
```

**Computation**:
```c
// Build computation graph
struct ggml_cgraph * ggml_new_graph(struct ggml_context * ctx);
void ggml_build_forward_expand(struct ggml_cgraph * cgraph, struct ggml_tensor * tensor);

// Execute graph
enum ggml_status ggml_graph_compute(struct ggml_cgraph * cgraph, struct ggml_cplan * cplan);

// Memory estimation
size_t ggml_graph_overhead(void);
size_t ggml_graph_overhead_custom(size_t size, bool grads);
```

---

#### [ggml/src/ggml.c](backend/whisper/whisper-source/ggml/src/ggml.c) (243 KB)

**Core Tensor Operations Implementation**

**Key Features**:
1. **Memory Management**: Arena allocator, zero fragmentation
2. **Computation Graphs**: Build once, compute many times
3. **Automatic Differentiation**: Backward pass computation
4. **Multi-threading**: Parallel computation
5. **SIMD Optimizations**: Platform-specific optimizations

---

#### [ggml/src/ggml-quants.c](backend/whisper/whisper-source/ggml/src/ggml-quants.c) (223 KB)

**Quantization Implementation**

**Supported Quantization Types**:
```c
enum ggml_type {
    GGML_TYPE_F32  = 0,   // float32
    GGML_TYPE_F16  = 1,   // float16
    GGML_TYPE_Q4_0 = 2,   // 4-bit quantization (type 0)
    GGML_TYPE_Q4_1 = 3,   // 4-bit quantization (type 1)
    GGML_TYPE_Q5_0 = 6,   // 5-bit quantization (type 0)
    GGML_TYPE_Q5_1 = 7,   // 5-bit quantization (type 1)
    GGML_TYPE_Q8_0 = 8,   // 8-bit quantization
    GGML_TYPE_Q8_1 = 9,   // 8-bit quantization (type 1)
    GGML_TYPE_Q2_K = 10,  // 2-bit K-quantization
    GGML_TYPE_Q3_K = 11,  // 3-bit K-quantization
    GGML_TYPE_Q4_K = 12,  // 4-bit K-quantization
    GGML_TYPE_Q5_K = 13,  // 5-bit K-quantization
    GGML_TYPE_Q6_K = 14,  // 6-bit K-quantization
    GGML_TYPE_Q8_K = 15,  // 8-bit K-quantization
    // ...
};
```

**Quantization Benefits**:
- **Q4_0**: ~4x smaller, ~10% accuracy loss
- **Q5_0**: ~3.2x smaller, ~5% accuracy loss
- **Q8_0**: ~2x smaller, ~2% accuracy loss

---

### 3. Go Binding Files

#### [bindings/go/whisper.go](backend/whisper/whisper-source/bindings/go/whisper.go)

**Low-level CGO Bindings**

```go
package whisper

/*
#cgo CFLAGS: -I${SRCDIR}/../../include
#cgo CXXFLAGS: -I${SRCDIR}/../../include -std=c++11
#cgo darwin,arm64 LDFLAGS: -L${SRCDIR}/../../build/src -lwhisper -framework Accelerate -lm -lstdc++
#cgo darwin,amd64 LDFLAGS: -L${SRCDIR}/../../build/src -lwhisper -framework Accelerate -lm -lstdc++
#cgo linux LDFLAGS: -L${SRCDIR}/../../build/src -lwhisper -lm -lstdc++
#cgo windows LDFLAGS: -L${SRCDIR}/../../build/src -lwhisper -lm -lstdc++

#include <whisper.h>
#include <stdlib.h>
*/
import "C"
import "unsafe"

// Context wrapper
type Context struct {
    ctx *C.struct_whisper_context
}

// Initialize from file
func NewContext(modelPath string) (*Context, error) {
    cModelPath := C.CString(modelPath)
    defer C.free(unsafe.Pointer(cModelPath))

    ctx := C.whisper_init_from_file(cModelPath)
    if ctx == nil {
        return nil, errors.New("failed to load model")
    }

    return &Context{ctx: ctx}, nil
}

// Free context
func (c *Context) Close() error {
    if c.ctx != nil {
        C.whisper_free(c.ctx)
        c.ctx = nil
    }
    return nil
}

// Transcribe audio
func (c *Context) Process(samples []float32, params *Params) error {
    cParams := paramsToC(params)

    ret := C.whisper_full(
        c.ctx,
        cParams,
        (*C.float)(unsafe.Pointer(&samples[0])),
        C.int(len(samples)),
    )

    if ret != 0 {
        return fmt.Errorf("whisper_full failed: %d", ret)
    }

    return nil
}

// Get segment count
func (c *Context) NumSegments() int {
    return int(C.whisper_full_n_segments(c.ctx))
}

// Get segment text
func (c *Context) SegmentText(index int) string {
    cText := C.whisper_full_get_segment_text(c.ctx, C.int(index))
    return C.GoString(cText)
}
```

---

#### [bindings/go/pkg/whisper/context.go](backend/whisper/whisper-source/bindings/go/pkg/whisper/context.go)

**High-level Go API**

```go
package whisper

// Model represents a loaded Whisper model
type Model interface {
    NewContext() (Context, error)
    Languages() []string
    Close() error
}

// Context represents a transcription context
type Context interface {
    SetLanguage(lang string) error
    SetTranslate(translate bool)
    SetThreads(threads int)

    Process(samples []float32, cb SegmentCallback) error

    IsBpe() bool
    IsMultilingual() bool

    Close() error
}

// SegmentCallback is called for each transcribed segment
type SegmentCallback func(segment Segment)

// Segment represents a transcribed text segment
type Segment struct {
    Num   int       // Segment number
    Text  string    // Transcribed text
    Start time.Duration // Start time
    End   time.Duration // End time
    Tokens []Token  // Token details
}

// Token represents a single token
type Token struct {
    Id    int       // Token ID
    Text  string    // Token text
    P     float32   // Probability
    Start time.Duration
    End   time.Duration
}
```

---

## Go Bindings

### à¸ à¸²à¸à¸£à¸§à¸¡

Go bindings à¸­à¸¢à¸¹à¹ˆà¹ƒà¸™ [bindings/go/](backend/whisper/whisper-source/bindings/go/) à¹ƒà¸Šà¹‰ **CGO** à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š C library

### à¹‚à¸„à¸£à¸‡à¸ªà¸£à¹‰à¸²à¸‡

```
bindings/go/
â”œâ”€â”€ whisper.go              # Low-level CGO bindings
â”œâ”€â”€ params.go               # Parameter structures
â”œâ”€â”€ go.mod                  # Module definition
â”œâ”€â”€ go.sum                  # Dependency checksums
â”œâ”€â”€ Makefile                # Build system
â”‚
â”œâ”€â”€ pkg/whisper/            # High-level API
â”‚   â”œâ”€â”€ interface.go        # Interface definitions
â”‚   â”œâ”€â”€ model.go            # Model management
â”‚   â”œâ”€â”€ context.go          # Context management
â”‚   â”œâ”€â”€ consts.go           # Constants
â”‚   â””â”€â”€ util_test.go        # Utility tests
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ go-whisper/         # CLI transcription tool
â”‚   â”‚   â”œâ”€â”€ main.go
â”‚   â”‚   â”œâ”€â”€ flags.go        # Command-line flags
â”‚   â”‚   â”œâ”€â”€ process.go      # Processing logic
â”‚   â”‚   â””â”€â”€ color.go        # Terminal colors
â”‚   â””â”€â”€ go-model-download/  # Model downloader
â”‚       â”œâ”€â”€ main.go
â”‚       â””â”€â”€ context.go
â”‚
â””â”€â”€ samples/
    â””â”€â”€ jfk.wav             # Test audio
```

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

#### 1. Build Library

```bash
cd backend/whisper/whisper-source
mkdir -p build
cd build
cmake ..
cmake --build . --config Release
```

à¸ˆà¸°à¹„à¸”à¹‰ `libwhisper.a` (static library) à¸«à¸£à¸·à¸­ `libwhisper.so` (shared library)

#### 2. Go Example

```go
package main

import (
    "fmt"
    "log"

    "github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper"
)

func main() {
    // Load model
    model, err := whisper.New("models/ggml-base.en.bin")
    if err != nil {
        log.Fatal(err)
    }
    defer model.Close()

    // Create context
    ctx, err := model.NewContext()
    if err != nil {
        log.Fatal(err)
    }
    defer ctx.Close()

    // Configure
    ctx.SetLanguage("en")
    ctx.SetThreads(4)

    // Load audio (16kHz, mono, float32)
    samples, err := loadAudio("audio.wav")
    if err != nil {
        log.Fatal(err)
    }

    // Process
    err = ctx.Process(samples, func(segment whisper.Segment) {
        fmt.Printf("[%6s -> %6s] %s\n",
            segment.Start,
            segment.End,
            segment.Text,
        )
    })

    if err != nil {
        log.Fatal(err)
    }
}
```

#### 3. Build with CUDA

```bash
# Build library with CUDA
cd backend/whisper/whisper-source/build
cmake -DGGML_CUDA=ON ..
cmake --build . --config Release

# Build Go app
cd ../bindings/go
GGML_CUDA=1 make
```

### Parameters

```go
type Params struct {
    Strategy    SamplingStrategy  // GREEDY or BEAM_SEARCH
    NThreads    int               // Number of threads
    Language    string            // "th", "en", "auto"
    Translate   bool              // Translate to English
    NoContext   bool              // No past context
    SingleSegment bool            // Single segment mode

    // Advanced
    MaxTextCtx  int               // Max text context (default: 16384)
    OffsetMs    int               // Audio offset (ms)
    DurationMs  int               // Audio duration (ms)

    // Timestamps
    NoTimestamps bool             // Disable timestamps
    TokenTimestamps bool          // Token-level timestamps

    // Beam search
    BeamSize    int               // Beam size (default: 5)
    BestOf      int               // Best of N (greedy)

    // Probabilities
    Temperature float32           // Sampling temperature
    MaxInitialTs float32          // Max initial timestamp

    // Prompt
    Prompt      string            // Initial prompt

    // Callbacks
    NewSegmentCallback func(Segment)
    ProgressCallback   func(int)
}
```

---

## GGML Framework

### à¸ à¸²à¸à¸£à¸§à¸¡

**GGML** (Georgi Gerganov Machine Learning) à¸„à¸·à¸­ tensor library à¸—à¸µà¹ˆà¸­à¸­à¸à¹à¸šà¸šà¸¡à¸²à¸ªà¸³à¸«à¸£à¸±à¸š:
- **Low-level optimizations**: SIMD, multi-threading
- **Zero runtime allocation**: Pre-allocated memory
- **Hardware acceleration**: CPU, GPU, NPU
- **Quantization**: Reduced precision for efficiency

**Location**: [ggml/](backend/whisper/whisper-source/ggml/)

### Core Concepts

#### 1. Tensors

**Tensor** = Multi-dimensional array + metadata

```c
struct ggml_tensor {
    enum ggml_type type;          // FP32, FP16, Q4_0, Q5_0, Q8_0, ...
    int64_t ne[GGML_MAX_DIMS];    // [dim0, dim1, dim2, dim3]
    size_t  nb[GGML_MAX_DIMS];    // Stride in bytes
    enum ggml_op op;              // Operation
    struct ggml_tensor * src[GGML_MAX_SRC]; // Inputs
    void * data;                  // Actual data
    char name[GGML_MAX_NAME];     // Debug name
};
```

**Example**: Matrix of size 512Ã—768 in FP16
```
type = GGML_TYPE_F16
ne = [512, 768, 1, 1]
nb = [2, 1024, 786432, 786432]  // Strides in bytes
data = pointer to 512*768*2 bytes
```

#### 2. Context (Memory Arena)

```c
struct ggml_context * ctx = ggml_init(params);

// All allocations within this context
struct ggml_tensor * a = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, 512, 768);
struct ggml_tensor * b = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, 768, 1024);

// Free all at once
ggml_free(ctx);
```

**Benefits**:
- No malloc/free overhead
- No memory fragmentation
- Fast allocation (bump allocator)

#### 3. Computation Graph

**Define-once, compute-many philosophy**:

```c
// 1. Define graph
struct ggml_cgraph * gf = ggml_new_graph(ctx);

struct ggml_tensor * a = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, M, K);
struct ggml_tensor * b = ggml_new_tensor_2d(ctx, GGML_TYPE_F32, K, N);

// c = matmul(a, b)
struct ggml_tensor * c = ggml_mul_mat(ctx, a, b);

// d = gelu(c)
struct ggml_tensor * d = ggml_gelu(ctx, c);

ggml_build_forward_expand(gf, d);

// 2. Compute (can be called multiple times with different data)
ggml_graph_compute_with_ctx(ctx, gf, n_threads);
```

**Graph Structure**:
```
Graph:
  Leafs: [a, b]           â† Input tensors
  Nodes: [c, d]           â† Intermediate/output tensors

Operations:
  c = mul_mat(a, b)       â† Matrix multiplication
  d = gelu(c)             â† GELU activation
```

### Backend System

GGML à¹ƒà¸Šà¹‰à¸£à¸°à¸šà¸š **backend abstraction** à¹à¸šà¸š pluggable:

```
Application
     â†“
ggml-backend.h (API)
     â†“
â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”´â”€â”€â”€â”€â”
â”‚         â”‚         â”‚         â”‚         â”‚
CPU     CUDA     Metal   Vulkan   SYCL
```

#### CPU Backend

[ggml/src/ggml-cpu/](backend/whisper/whisper-source/ggml/src/ggml-cpu/)

**Features**:
- **SIMD**: AVX, AVX2, AVX512, NEON, VSX
- **Multi-threading**: OpenMP, pthread
- **BLAS**: OpenBLAS, Intel MKL, Apple Accelerate
- **Quantization**: Q4_0, Q5_0, Q8_0

**Optimizations**:
```cpp
// AVX2 example (8 floats at a time)
__m256 a = _mm256_loadu_ps(ptr_a);
__m256 b = _mm256_loadu_ps(ptr_b);
__m256 c = _mm256_add_ps(a, b);
_mm256_storeu_ps(ptr_c, c);
```

#### CUDA Backend

[ggml/src/ggml-cuda/](backend/whisper/whisper-source/ggml/src/ggml-cuda/)

**Features**:
- **GPU acceleration**: NVIDIA GPUs
- **cuBLAS**: Optimized matrix operations
- **Mixed precision**: FP16/FP32
- **Multi-GPU**: Tensor/pipeline parallelism

**Example Kernel**:
```cuda
__global__ void add_kernel(const float *a, const float *b, float *c, int n) {
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    if (i < n) {
        c[i] = a[i] + b[i];
    }
}
```

#### Metal Backend

[ggml/src/ggml-metal/](backend/whisper/whisper-source/ggml/src/ggml-metal/)

**Features**:
- **Apple Silicon**: M1, M2, M3, M4 chips
- **Unified memory**: Zero-copy data sharing
- **Metal Performance Shaders (MPS)**
- **Neural Engine support**

#### Vulkan Backend

[ggml/src/ggml-vulkan/](backend/whisper/whisper-source/ggml/src/ggml-vulkan/)

**Features**:
- **Cross-platform**: Windows, Linux, Android
- **Wide GPU support**: NVIDIA, AMD, Intel, ARM Mali
- **Compute shaders**: SPIR-V

### Quantization

**Goal**: Reduce model size and memory bandwidth

#### Quantization Types

| Type   | Bits/Weight | Memory | Accuracy Loss |
|--------|-------------|--------|---------------|
| FP32   | 32          | 1.0x   | 0% (baseline) |
| FP16   | 16          | 0.5x   | ~0.1%         |
| Q8_0   | 8           | 0.25x  | ~1%           |
| Q5_1   | 5.5         | 0.17x  | ~3%           |
| Q5_0   | 5           | 0.16x  | ~5%           |
| Q4_1   | 4.5         | 0.14x  | ~7%           |
| Q4_0   | 4           | 0.125x | ~10%          |

#### Q4_0 Format

**Block-wise quantization** (32 values per block):

```c
struct block_q4_0 {
    ggml_half d;      // Delta (scale factor)
    uint8_t qs[16];   // Quantized values (2 per byte)
};

// Dequantization:
// value = d * (quantized_value - 8)
```

**Example**:
```
Original (FP32): [0.5, 0.6, 0.7, ..., 1.5]
â†“
Quantized (Q4_0):
  d = 0.1 (scale)
  qs = [5, 6, 7, ..., 15]  (4-bit integers: 0-15)
â†“
Reconstructed: [0.5, 0.6, 0.7, ..., 1.5]
```

#### Quantization Tools

```bash
# Quantize model to Q5_0
./examples/quantize models/ggml-base.en.bin models/ggml-base.en-q5_0.bin q5_0

# Compare accuracy
./examples/bench -m models/ggml-base.en.bin
./examples/bench -m models/ggml-base.en-q5_0.bin
```

---

## à¸à¸²à¸£à¸—à¸³à¸‡à¸²à¸™à¸‚à¸­à¸‡ Whisper

### Pipeline Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WHISPER PIPELINE                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. AUDIO INPUT
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Raw Audio        â”‚
   â”‚  (any format)     â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Resample to      â”‚
   â”‚  16 kHz mono      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Normalize to     â”‚
   â”‚  [-1.0, 1.0]      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“

2. MEL SPECTROGRAM EXTRACTION
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Split into       â”‚
   â”‚  30-sec chunks    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  FFT              â”‚
   â”‚  window: 400      â”‚
   â”‚  hop: 160         â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Apply Mel        â”‚
   â”‚  filterbank       â”‚
   â”‚  (80 channels)    â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Log scale        â”‚
   â”‚  Normalize        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
         [3000 Ã— 80]    â† Mel spectrogram tensor

3. ENCODER
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Conv1D (1)       â”‚ â† Extract features
   â”‚  stride: 1        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  GELU activation  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Conv1D (2)       â”‚ â† Downsample 2x
   â”‚  stride: 2        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  GELU activation  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Positional       â”‚ â† Add position info
   â”‚  embedding        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘  Transformer      â•‘ â† Repeat N times
   â•‘  Block Ã—N         â•‘   (4, 6, 12, 24, or 32)
   â•‘                   â•‘
   â•‘  â€¢ Layer norm     â•‘
   â•‘  â€¢ Self-attention â•‘
   â•‘  â€¢ Residual       â•‘
   â•‘  â€¢ Layer norm     â•‘
   â•‘  â€¢ MLP (FFN)      â•‘
   â•‘  â€¢ Residual       â•‘
   â•šâ•â•â•â•â•â•â•â”¬â•â•â•â•â•â•â•â•â•â•â•â•
           â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Final layer norm â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
      [1500 Ã— 512/768/1024/1280]  â† Audio embeddings

4. DECODER (Autoregressive)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Start token      â”‚ â† <|startoftranscript|>
   â”‚  + Language token â”‚   <|en|> or <|th|>
   â”‚  + Task token     â”‚   <|transcribe|> or <|translate|>
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
   â•‘  Loop until       â•‘
   â•‘  <|endoftext|>    â•‘
   â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
   â•‘                   â•‘
   â•‘  Token embedding  â•‘ â† Current tokens
   â•‘        +          â•‘
   â•‘  Positional emb.  â•‘
   â•‘        â†“          â•‘
   â•‘  â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®â•‘
   â•‘  â”‚ Transformer   â”‚â•‘ â† Repeat N times
   â•‘  â”‚ Block Ã—N      â”‚â•‘
   â•‘  â”‚               â”‚â•‘
   â•‘  â”‚ â€¢ Layer norm  â”‚â•‘
   â•‘  â”‚ â€¢ Self-attn   â”‚â•‘ â† Attend to previous tokens
   â•‘  â”‚ â€¢ Residual    â”‚â•‘
   â•‘  â”‚ â€¢ Layer norm  â”‚â•‘
   â•‘  â”‚ â€¢ Cross-attn  â”‚â•‘ â† Attend to encoder output
   â•‘  â”‚ â€¢ Residual    â”‚â•‘
   â•‘  â”‚ â€¢ Layer norm  â”‚â•‘
   â•‘  â”‚ â€¢ MLP (FFN)   â”‚â•‘
   â•‘  â”‚ â€¢ Residual    â”‚â•‘
   â•‘  â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯â•‘
   â•‘        â†“          â•‘
   â•‘  Final layer norm â•‘
   â•‘        â†“          â•‘
   â•‘  Linear projectionâ•‘ â† [vocab_size] logits
   â•‘        â†“          â•‘
   â•‘  Softmax          â•‘
   â•‘        â†“          â•‘
   â•‘  Sample token     â•‘ â† Greedy or beam search
   â•‘        â†“          â•‘
   â•‘  Append & repeat  â•‘
   â•‘                   â•‘
   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
             â†“

5. POST-PROCESSING
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Token sequence   â”‚
   â”‚  [tokens...]      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Decode tokens    â”‚ â† Token IDs â†’ Text
   â”‚  to text          â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Extract          â”‚ â† Timestamp tokens
   â”‚  timestamps       â”‚   <|0.00|>, <|0.02|>, ...
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Remove special   â”‚ â† <|notimestamps|>, etc.
   â”‚  tokens           â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Final            â”‚
   â”‚  transcription    â”‚ â† Text + timestamps
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detailed Steps

#### 1. Audio Preprocessing

**Input**: Raw audio (any sample rate, channels)
**Output**: 16 kHz mono float32 array

```cpp
// Resample to 16 kHz
std::vector<float> pcm16k = resample_audio(audio, sample_rate, 16000);

// Convert to mono (if stereo)
if (n_channels == 2) {
    for (int i = 0; i < n_samples/2; i++) {
        pcm16k[i] = (pcm16k[2*i] + pcm16k[2*i+1]) / 2.0f;
    }
}

// Normalize to [-1.0, 1.0]
float max_val = *std::max_element(pcm16k.begin(), pcm16k.end());
for (auto & sample : pcm16k) {
    sample /= max_val;
}
```

#### 2. Mel Spectrogram

**Process**:
1. Split audio into overlapping windows (25ms window, 10ms hop)
2. Apply Hann window
3. Compute FFT
4. Apply mel filterbank (80 channels)
5. Convert to log scale

```cpp
// Parameters
const int n_fft = 400;          // FFT size (25ms at 16kHz)
const int hop_length = 160;     // Hop length (10ms)
const int n_mels = 80;          // Mel channels

// Mel filterbank
std::vector<float> mel_filters[n_mels];
build_mel_filters(mel_filters, n_fft, n_mels, 0.0, 8000.0);

// Compute spectrogram
for (int i = 0; i < n_frames; i++) {
    // Extract window
    std::vector<float> window(n_fft);
    for (int j = 0; j < n_fft; j++) {
        window[j] = pcm16k[i * hop_length + j] * hann_window[j];
    }

    // FFT
    std::vector<std::complex<float>> fft_result = fft(window);

    // Power spectrum
    std::vector<float> power(n_fft / 2 + 1);
    for (int j = 0; j < power.size(); j++) {
        power[j] = std::norm(fft_result[j]);
    }

    // Apply mel filters
    for (int j = 0; j < n_mels; j++) {
        float mel_val = 0.0f;
        for (int k = 0; k < power.size(); k++) {
            mel_val += power[k] * mel_filters[j][k];
        }
        mel[i][j] = log10(std::max(mel_val, 1e-10f));
    }
}

// Normalize
normalize_mel(mel);
```

**Result**: Tensor of shape `[n_frames, 80]` (typically `[3000, 80]` for 30 seconds)

#### 3. Encoder

**Architecture**:
```
Input: [3000, 80] mel spectrogram
  â†“
Conv1D(in=80, out=384/512/768/1024, kernel=3, stride=1)
  â†“ [3000, hidden_dim]
GELU
  â†“
Conv1D(in=hidden_dim, out=hidden_dim, kernel=3, stride=2)
  â†“ [1500, hidden_dim]  â† Downsampled 2x
GELU
  â†“
Positional Embedding [1500, hidden_dim]
  â†“
Transformer Block Ã—N:
  â”œâ”€ LayerNorm
  â”œâ”€ MultiHeadAttention (self)
  â”‚   Q, K, V = Linear(x)
  â”‚   Attention = softmax(QÂ·K^T / sqrt(d_k))
  â”‚   Output = Attention Â· V
  â”œâ”€ Residual connection
  â”œâ”€ LayerNorm
  â”œâ”€ MLP (2-layer FFN)
  â”‚   FFN = GELU(Linear(x))
  â”‚   Output = Linear(FFN)
  â””â”€ Residual connection
  â†“
LayerNorm
  â†“
Output: [1500, hidden_dim] audio embeddings
```

**Model Sizes**:
- **tiny**: 4 layers, 384 dims, 6 heads
- **base**: 6 layers, 512 dims, 8 heads
- **small**: 12 layers, 768 dims, 12 heads
- **medium**: 24 layers, 1024 dims, 16 heads
- **large**: 32 layers, 1280 dims, 20 heads

#### 4. Decoder

**Special Tokens**:
```
<|startoftranscript|>   = 50258
<|en|>                  = 50259  (English)
<|th|>                  = 50316  (Thai)
<|transcribe|>          = 50359
<|translate|>           = 50358
<|notimestamps|>        = 50363
<|0.00|> to <|30.00|>   = 50364 to 51864  (timestamps)
<|endoftext|>           = 50257
```

**Decoding Process**:

```python
# Initial tokens
tokens = [
    <|startoftranscript|>,
    <|th|>,              # Language
    <|transcribe|>,      # Task
    <|notimestamps|>     # Optional
]

# Autoregressive generation
while True:
    # 1. Token embeddings
    x = token_embedding[tokens] + positional_embedding[:len(tokens)]

    # 2. Decoder layers
    for layer in decoder_layers:
        # Self-attention (causal mask)
        x = layer.self_attn(x, x, x, causal_mask=True)
        x = layer.norm1(x)

        # Cross-attention to encoder
        x = layer.cross_attn(x, encoder_output, encoder_output)
        x = layer.norm2(x)

        # Feed-forward
        x = layer.mlp(x)
        x = layer.norm3(x)

    # 3. Project to vocabulary
    logits = linear_projection(x[-1])  # Last token

    # 4. Sample next token
    if strategy == GREEDY:
        next_token = argmax(logits)
    elif strategy == BEAM_SEARCH:
        next_token = beam_search(logits, beam_size=5)

    # 5. Append token
    tokens.append(next_token)

    # 6. Check termination
    if next_token == <|endoftext|> or len(tokens) >= max_length:
        break

# 7. Decode to text
text = tokenizer.decode(tokens)
```

**Beam Search**:

```cpp
struct beam_candidate {
    std::vector<int> tokens;    // Token sequence
    double log_prob;            // Cumulative log probability
    bool completed;             // Ended with <|endoftext|>
};

std::vector<beam_candidate> beams = { initial_beam };

for (int step = 0; step < max_steps; step++) {
    std::vector<beam_candidate> next_beams;

    // Expand each beam
    for (auto & beam : beams) {
        if (beam.completed) {
            next_beams.push_back(beam);
            continue;
        }

        // Get logits for current beam
        auto logits = decoder_forward(beam.tokens);
        auto probs = softmax(logits);

        // Get top-k candidates
        auto top_k = get_top_k(probs, beam_size);

        for (auto [token, prob] : top_k) {
            beam_candidate new_beam = beam;
            new_beam.tokens.push_back(token);
            new_beam.log_prob += log(prob);

            if (token == END_TOKEN) {
                new_beam.completed = true;
            }

            next_beams.push_back(new_beam);
        }
    }

    // Keep top beam_size beams
    std::sort(next_beams.begin(), next_beams.end(),
        [](auto &a, auto &b) { return a.log_prob > b.log_prob; });

    beams = std::vector<beam_candidate>(
        next_beams.begin(),
        next_beams.begin() + beam_size
    );
}

// Return best beam
return beams[0];
```

#### 5. Timestamp Detection

Whisper à¸ªà¸²à¸¡à¸²à¸£à¸– predict timestamps à¹„à¸”à¹‰à¹‚à¸”à¸¢à¹ƒà¸Šà¹‰ special tokens:

```
Text tokens:        Hello, how are you today?
Timestamp tokens:   <|0.00|> <|1.20|> <|2.50|> <|4.00|>

Result:
[0.00s - 1.20s]: Hello,
[1.20s - 2.50s]: how are you
[2.50s - 4.00s]: today?
```

**VAD (Voice Activity Detection)** à¸ªà¸²à¸¡à¸²à¸£à¸–à¹ƒà¸Šà¹‰à¸£à¹ˆà¸§à¸¡à¸à¸±à¸š timestamps à¹€à¸à¸·à¹ˆà¸­à¸•à¸±à¸”à¸Šà¹ˆà¸§à¸‡à¸—à¸µà¹ˆà¹„à¸¡à¹ˆà¸¡à¸µà¹€à¸ªà¸µà¸¢à¸‡à¸à¸¹à¸”

---

## Hardware Acceleration

### CPU Optimizations

#### SIMD Instructions

**AVX2 Example** (8 float32 operations at once):
```cpp
// Scalar code (slow)
for (int i = 0; i < n; i++) {
    c[i] = a[i] + b[i];
}

// AVX2 code (8x faster)
for (int i = 0; i < n; i += 8) {
    __m256 va = _mm256_loadu_ps(&a[i]);
    __m256 vb = _mm256_loadu_ps(&b[i]);
    __m256 vc = _mm256_add_ps(va, vb);
    _mm256_storeu_ps(&c[i], vc);
}
```

**NEON Example** (ARM):
```cpp
for (int i = 0; i < n; i += 4) {
    float32x4_t va = vld1q_f32(&a[i]);
    float32x4_t vb = vld1q_f32(&b[i]);
    float32x4_t vc = vaddq_f32(va, vb);
    vst1q_f32(&c[i], vc);
}
```

#### BLAS Libraries

**OpenBLAS**, **Intel MKL**, **Apple Accelerate** à¹ƒà¸«à¹‰ optimized matrix operations:

```cpp
// GEMM: C = Î±Â·AÂ·B + Î²Â·C
cblas_sgemm(
    CblasRowMajor,      // Layout
    CblasNoTrans,       // No transpose A
    CblasNoTrans,       // No transpose B
    M, N, K,            // Dimensions
    alpha,              // Scalar Î±
    A, K,               // Matrix A
    B, N,               // Matrix B
    beta,               // Scalar Î²
    C, N                // Matrix C
);
```

**Performance**: 10-100x faster than naive loops

### NVIDIA CUDA

**Build**:
```bash
cmake -DGGML_CUDA=ON ..
cmake --build . --config Release
```

**Kernel Example**:
```cuda
// Matrix multiplication kernel
__global__ void matmul_kernel(
    const float *A, const float *B, float *C,
    int M, int N, int K
) {
    int row = blockIdx.y * blockDim.y + threadIdx.y;
    int col = blockIdx.x * blockDim.x + threadIdx.x;

    if (row < M && col < N) {
        float sum = 0.0f;
        for (int k = 0; k < K; k++) {
            sum += A[row * K + k] * B[k * N + col];
        }
        C[row * N + col] = sum;
    }
}

// Launch kernel
dim3 block(16, 16);
dim3 grid((N + 15) / 16, (M + 15) / 16);
matmul_kernel<<<grid, block>>>(A, B, C, M, N, K);
```

**Performance**: 50-200x faster than CPU (depending on model size)

### Apple Metal

**Build**:
```bash
cmake -DGGML_METAL=ON ..
cmake --build . --config Release
```

**Metal Shader Example**:
```metal
kernel void add_arrays(
    device const float* a [[buffer(0)]],
    device const float* b [[buffer(1)]],
    device float* c [[buffer(2)]],
    uint id [[thread_position_in_grid]]
) {
    c[id] = a[id] + b[id];
}
```

**Advantages**:
- **Unified Memory**: No CPUâ†”GPU copies
- **Neural Engine**: Dedicated ML accelerator
- **Low Power**: Efficient for laptops/mobile

**Performance on M1 Max**: ~100x faster than CPU

### Vulkan

**Build**:
```bash
cmake -DGGML_VULKAN=ON ..
cmake --build . --config Release
```

**Cross-platform**: Works on NVIDIA, AMD, Intel, ARM Mali GPUs

### Performance Comparison

| Hardware | Model | Speed (realtime factor) | Power |
|----------|-------|-------------------------|-------|
| CPU (Intel i9-12900K) | base | 0.3x | 125W |
| CPU + AVX2 | base | 1.0x | 125W |
| NVIDIA RTX 4090 | base | 50x | 450W |
| Apple M1 Max (Metal) | base | 100x | 30W |
| Apple M1 Max (Neural Engine) | base | 150x | 20W |

**Realtime factor**: 10x = process 10 seconds of audio in 1 second

---

## à¸•à¸±à¸§à¸­à¸¢à¹ˆà¸²à¸‡à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™

### 1. Command-line Tool

[examples/cli/cli.cpp](backend/whisper/whisper-source/examples/cli/cli.cpp)

```bash
# Transcribe audio file
./cli \
    -m models/ggml-base.en.bin \
    -f audio.wav \
    -t 4 \
    -l en

# With timestamps
./cli -m models/ggml-base.bin -f audio.wav -t 8 --print-timestamps

# Translate to English
./cli -m models/ggml-base.bin -f audio.wav --translate

# Real-time streaming
./cli -m models/ggml-base.bin -c 0 -t 8
```

### 2. Real-time Streaming

[examples/stream/stream.cpp](backend/whisper/whisper-source/examples/stream/stream.cpp)

```cpp
// Capture audio from microphone
SDL_AudioSpec capture_spec;
capture_spec.freq = 16000;
capture_spec.format = AUDIO_F32;
capture_spec.channels = 1;
capture_spec.samples = 512;

// Initialize Whisper
auto ctx = whisper_init_from_file(model_path);

// Process audio in chunks
std::vector<float> audio_buffer;
while (true) {
    // Capture audio
    SDL_LockAudioDevice(device);
    audio_buffer.insert(audio_buffer.end(),
        pcm_capture.begin(), pcm_capture.end());
    SDL_UnlockAudioDevice(device);

    // Process when buffer is full (3 seconds)
    if (audio_buffer.size() >= 16000 * 3) {
        auto params = whisper_full_default_params(WHISPER_SAMPLING_GREEDY);
        params.print_realtime = true;

        whisper_full(ctx, params, audio_buffer.data(), audio_buffer.size());

        // Clear buffer
        audio_buffer.clear();
    }
}
```

### 3. HTTP Server

[examples/server/server.cpp](backend/whisper/whisper-source/examples/server/server.cpp)

**OpenAI-compatible API**:

```bash
# Start server
./server -m models/ggml-base.bin -p 8080

# Upload audio
curl http://localhost:8080/inference \
    -F file="@audio.wav" \
    -F temperature="0.0" \
    -F language="en"

# Response
{
    "text": "Hello, how are you today?",
    "segments": [
        {
            "start": 0.0,
            "end": 1.5,
            "text": "Hello,"
        },
        {
            "start": 1.5,
            "end": 3.0,
            "text": " how are you today?"
        }
    ]
}
```

### 4. Voice Commands

[examples/command/command.cpp](backend/whisper/whisper-source/examples/command/command.cpp)

```cpp
// Define commands
const std::vector<std::string> commands = {
    "turn on the lights",
    "turn off the lights",
    "set temperature to [number]",
    "play music",
    "stop"
};

// Initialize with grammar
auto params = whisper_full_default_params(WHISPER_SAMPLING_GREEDY);
params.grammar = load_grammar("commands.gbnf");

// Process audio
whisper_full(ctx, params, audio.data(), audio.size());

// Get result
std::string text = whisper_full_get_segment_text(ctx, 0);

// Match command
for (auto & cmd : commands) {
    if (match(text, cmd)) {
        execute_command(cmd);
        break;
    }
}
```

### 5. Go Example

```go
package main

import (
    "fmt"
    "log"
    "os"

    whisper "github.com/ggerganov/whisper.cpp/bindings/go/pkg/whisper"
)

func main() {
    // Load model
    model, err := whisper.New("models/ggml-base.bin")
    if err != nil {
        log.Fatal(err)
    }
    defer model.Close()

    // Create context
    ctx, err := model.NewContext()
    if err != nil {
        log.Fatal(err)
    }
    defer ctx.Close()

    // Configure
    ctx.SetLanguage("th")  // Thai language
    ctx.SetThreads(4)
    ctx.SetTranslate(false)

    // Load audio (16kHz, mono, float32)
    samples, err := loadWavFile("audio.wav")
    if err != nil {
        log.Fatal(err)
    }

    // Process with callback
    err = ctx.Process(samples, func(segment whisper.Segment) {
        fmt.Printf("[%6.2fs -> %6.2fs] %s\n",
            segment.Start.Seconds(),
            segment.End.Seconds(),
            segment.Text,
        )
    })

    if err != nil {
        log.Fatal(err)
    }
}

// Load WAV file (16kHz, mono)
func loadWavFile(path string) ([]float32, error) {
    // Implementation...
    // Convert WAV to float32 samples at 16kHz
}
```

---

## à¸ªà¸£à¸¸à¸›

### à¸ˆà¸¸à¸”à¹€à¸”à¹ˆà¸™à¸‚à¸­à¸‡ Whisper.cpp

1. **à¸›à¸£à¸°à¸ªà¸´à¸—à¸˜à¸´à¸ à¸²à¸à¸ªà¸¹à¸‡**: Optimized C/C++ code + SIMD + GPU acceleration
2. **à¹„à¸¡à¹ˆà¸•à¹‰à¸­à¸‡à¸à¸¶à¹ˆà¸‡ dependencies**: Static linking, no Python/PyTorch required
3. **Cross-platform**: Linux, macOS, Windows, iOS, Android, WebAssembly
4. **Quantization**: à¸¥à¸”à¸‚à¸™à¸²à¸”à¹‚à¸¡à¹€à¸”à¸¥ 3-4 à¹€à¸—à¹ˆà¸² à¹‚à¸”à¸¢à¸¢à¸±à¸‡à¸„à¸‡à¸„à¸§à¸²à¸¡à¹à¸¡à¹ˆà¸™à¸¢à¸³
5. **Flexible**: à¸«à¸¥à¸²à¸¢ backends (CPU, CUDA, Metal, Vulkan, Core ML)
6. **Production-ready**: Stable API, comprehensive examples
7. **Multi-language bindings**: Go, Java, JavaScript, Ruby

### à¸à¸²à¸£à¹ƒà¸Šà¹‰à¸‡à¸²à¸™à¹ƒà¸™à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸™à¸µà¹‰

à¹‚à¸›à¸£à¹€à¸ˆà¹‡à¸„à¸™à¸µà¹‰à¹ƒà¸Šà¹‰ **Go bindings** à¹€à¸Šà¸·à¹ˆà¸­à¸¡à¸•à¹ˆà¸­à¸à¸±à¸š **libwhisper.a** (static library) à¸—à¸µà¹ˆ build à¸ˆà¸²à¸ C++ source code

**Flow**:
```
Go Application
     â†“ (CGO)
Go Bindings (bindings/go/)
     â†“
libwhisper.a (C++ library)
     â†“
GGML (tensor operations)
     â†“
Hardware (CPU/GPU)
```

### à¸‚à¹‰à¸­à¸¡à¸¹à¸¥à¹€à¸à¸´à¹ˆà¸¡à¹€à¸•à¸´à¸¡

- **GitHub**: https://github.com/ggerganov/whisper.cpp
- **Main README**: [README.md](backend/whisper/whisper-source/README.md)
- **Go Bindings README**: [bindings/go/README.md](backend/whisper/whisper-source/bindings/go/README.md)
- **GGML**: https://github.com/ggerganov/ggml
- **OpenAI Whisper**: https://github.com/openai/whisper

---

**à¹€à¸­à¸à¸ªà¸²à¸£à¸™à¸µà¹‰à¸ªà¸£à¹‰à¸²à¸‡à¹‚à¸”à¸¢**: Claude Code
**à¸§à¸±à¸™à¸—à¸µà¹ˆ**: 2025-11-10
**à¹€à¸§à¸­à¸£à¹Œà¸Šà¸±à¸™**: Whisper.cpp 1.8.2
